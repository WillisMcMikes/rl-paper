{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SlimeVolleyGym_Will.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "interpreter": {
      "hash": "07ae59c8b0d6338d1589a809f6cf35bc0e76d5b74b3f273ecf375c8057405647"
    },
    "kernelspec": {
      "display_name": "Python 3.8.10 64-bit ('mava': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bmS359b1IMIh",
        "outputId": "eb14b20f-594e-478e-83ad-70b029eb653b"
      },
      "source": [
        "!pip install slimevolleygym dm-sonnet trfl wandb"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting slimevolleygym\n",
            "  Downloading slimevolleygym-0.1.0-py3-none-any.whl (17 kB)\n",
            "Collecting dm-sonnet\n",
            "  Downloading dm_sonnet-2.0.0-py3-none-any.whl (254 kB)\n",
            "\u001b[K     |████████████████████████████████| 254 kB 8.4 MB/s \n",
            "\u001b[?25hCollecting trfl\n",
            "  Downloading trfl-1.2.0-py3-none-any.whl (104 kB)\n",
            "\u001b[K     |████████████████████████████████| 104 kB 50.3 MB/s \n",
            "\u001b[?25hCollecting wandb\n",
            "  Downloading wandb-0.12.6-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 42.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from slimevolleygym) (1.19.5)\n",
            "Requirement already satisfied: gym>=0.9.4 in /usr/local/lib/python3.7/dist-packages (from slimevolleygym) (0.17.3)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym>=0.9.4->slimevolleygym) (1.5.0)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym>=0.9.4->slimevolleygym) (1.3.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym>=0.9.4->slimevolleygym) (1.4.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym>=0.9.4->slimevolleygym) (0.16.0)\n",
            "Requirement already satisfied: tabulate>=0.7.5 in /usr/local/lib/python3.7/dist-packages (from dm-sonnet) (0.8.9)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from dm-sonnet) (1.15.0)\n",
            "Requirement already satisfied: dm-tree>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from dm-sonnet) (0.1.6)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from dm-sonnet) (1.13.3)\n",
            "Requirement already satisfied: absl-py>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from dm-sonnet) (0.12.0)\n",
            "Collecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.4.3-py2.py3-none-any.whl (139 kB)\n",
            "\u001b[K     |████████████████████████████████| 139 kB 63.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Downloading shortuuid-1.0.7-py3-none-any.whl (8.6 kB)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n",
            "Collecting GitPython>=1.0.0\n",
            "  Downloading GitPython-3.1.24-py3-none-any.whl (180 kB)\n",
            "\u001b[K     |████████████████████████████████| 180 kB 60.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Collecting configparser>=3.8.1\n",
            "  Downloading configparser-5.1.0-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (3.13)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.2)\n",
            "Collecting yaspin>=1.0.0\n",
            "  Downloading yaspin-2.1.0-py3-none-any.whl (18 kB)\n",
            "Collecting subprocess32>=3.5.3\n",
            "  Downloading subprocess32-3.5.4.tar.gz (97 kB)\n",
            "\u001b[K     |████████████████████████████████| 97 kB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (3.10.0.2)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.4 MB/s \n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied: termcolor<2.0.0,>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from yaspin>=1.0.0->wandb) (1.1.0)\n",
            "Building wheels for collected packages: subprocess32, pathtools\n",
            "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for subprocess32: filename=subprocess32-3.5.4-py3-none-any.whl size=6502 sha256=2a686d50ab9eb306f43bc37de11cc377636cf23a0994c4c74098f29066eca460\n",
            "  Stored in directory: /root/.cache/pip/wheels/50/ca/fa/8fca8d246e64f19488d07567547ddec8eb084e8c0d7a59226a\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8807 sha256=404dca8a379e8dd66ba0721b2e90bef67607f6f6f1d18a278906849eb1e0d916\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n",
            "Successfully built subprocess32 pathtools\n",
            "Installing collected packages: smmap, gitdb, yaspin, subprocess32, shortuuid, sentry-sdk, pathtools, GitPython, docker-pycreds, configparser, wandb, trfl, slimevolleygym, dm-sonnet\n",
            "Successfully installed GitPython-3.1.24 configparser-5.1.0 dm-sonnet-2.0.0 docker-pycreds-0.4.0 gitdb-4.0.9 pathtools-0.1.2 sentry-sdk-1.4.3 shortuuid-1.0.7 slimevolleygym-0.1.0 smmap-5.0.0 subprocess32-3.5.4 trfl-1.2.0 wandb-0.12.6 yaspin-2.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ZLv0_RSNq2c"
      },
      "source": [
        "import gym\n",
        "import slimevolleygym\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from typing import NamedTuple\n",
        "import sonnet as snt\n",
        "import trfl\n",
        "import copy\n",
        "import wandb\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1lqTRl72N1uF"
      },
      "source": [
        "ACTION_LOOKUP = [\n",
        "  [0, 0, 0], # NOOP\n",
        "  [1, 0, 0], # LEFT (forward)\n",
        "  [1, 0, 1], # UPLEFT (forward jump)\n",
        "  [0, 0, 1], # UP (jump)\n",
        "  [0, 1, 1], # UPRIGHT (backward jump)\n",
        "  [0, 1, 0]  # RIGHT (backward)\n",
        "] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1jWMEx_N80f"
      },
      "source": [
        "\n",
        "# def random_policy(obs):\n",
        "#   action_id = np.random.randint(6)\n",
        "#   return ACTION_LOOKUP[action_id], action_id\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMFJ_AP4OB79"
      },
      "source": [
        "# def run_one_episode(policy, env):\n",
        "#   obs = env.reset()\n",
        "#   done = False\n",
        "#   total_reward = 0\n",
        "\n",
        "#   while not done:\n",
        "#     action, action_id = policy(obs)\n",
        "#     obs, reward, done, info = env.step(action)\n",
        "#     total_reward += reward\n",
        "#     # env.render()\n",
        "\n",
        "#   return total_reward"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tXbW6UfOFlh"
      },
      "source": [
        "env = gym.make(\"SlimeVolley-v0\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "daustD1ROOcJ",
        "outputId": "c3092890-4964-4e0e-977b-2eda7b4b20e2"
      },
      "source": [
        "# returns = []\n",
        "# for episode in range(100):\n",
        "#   reward = run_one_episode(random_policy, env)\n",
        "#   returns.append(reward)\n",
        "  \n",
        "# print(\"av. returns = \", np.mean(returns))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "av. returns =  -4.82\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aIJ6yebgO80t"
      },
      "source": [
        "class Batch(NamedTuple):\n",
        "    \"\"\"Container for a batch of experience tuples.\"\"\"\n",
        "    observation: np.array\n",
        "    next_observation: np.array\n",
        "    reward: np.array\n",
        "    action: np.array\n",
        "    done: np.array\n",
        "\n",
        "\n",
        "class TransitionBuffer:\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        observation_dim,\n",
        "        buffer_size=5000,  # Num episodes\n",
        "        batch_size=32\n",
        "    ):\n",
        "        self.observation_dim = observation_dim\n",
        "        self.buffer_size = buffer_size\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        observation_buffer_shape = (buffer_size, observation_dim)\n",
        "        self.observation_buffer = np.zeros(observation_buffer_shape, dtype='float32')\n",
        "        self.next_observation_buffer = np.zeros(observation_buffer_shape, dtype='float32')\n",
        "\n",
        "        action_buffer_shape = (buffer_size, )\n",
        "        self.action_buffer = np.zeros(action_buffer_shape, dtype='int32')\n",
        "        self.reward_buffer = np.zeros(action_buffer_shape, dtype='float32')\n",
        "        self.dones_buffer = np.zeros(action_buffer_shape, dtype='float32')\n",
        "\n",
        "        self.counter = 0\n",
        "\n",
        "    def can_sample_batch(self):\n",
        "        return self.counter >= self.batch_size  # Cannot sample more than the batch size\n",
        "\n",
        "    def add(\n",
        "        self,\n",
        "        batch: Batch,\n",
        "    ):\n",
        "        idx = self.counter % self.buffer_size  # FIFO\n",
        "\n",
        "        self.observation_buffer[idx] = batch.observation\n",
        "        self.next_observation_buffer[idx] = batch.next_observation\n",
        "        self.action_buffer[idx] = batch.action\n",
        "        self.reward_buffer[idx] = batch.reward\n",
        "        self.dones_buffer[idx] = batch.done\n",
        "\n",
        "        self.counter += 1\n",
        "\n",
        "    def sample(self):\n",
        "        assert self.can_sample_batch()\n",
        "\n",
        "        max_idx = min(self.counter, self.buffer_size)\n",
        "        idxs = np.random.choice(max_idx, size=self.batch_size, replace=True)\n",
        "\n",
        "        observation_batch = tf.convert_to_tensor(self.observation_buffer[idxs])\n",
        "        next_observation_batch = tf.convert_to_tensor(self.next_observation_buffer[idxs])\n",
        "        action_batch = tf.convert_to_tensor(self.action_buffer[idxs])\n",
        "        reward_batch = tf.convert_to_tensor(self.reward_buffer[idxs])\n",
        "        dones_batch = tf.convert_to_tensor(self.dones_buffer[idxs])\n",
        "\n",
        "        batch = Batch(\n",
        "            observation=observation_batch,\n",
        "            next_observation=next_observation_batch,\n",
        "            action=action_batch,\n",
        "            reward=reward_batch,\n",
        "            done=dones_batch,\n",
        "        )\n",
        "\n",
        "        return batch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EC0wRQ1FPY-j"
      },
      "source": [
        "# def run_one_episode(policy, env, replay):\n",
        "#   obs = env.reset()\n",
        "#   done = False\n",
        "#   total_reward = 0\n",
        "\n",
        "#   while not done:\n",
        "#     action, action_id = policy(obs)\n",
        "#     next_obs, reward, done, info = env.step(action)\n",
        "#     batch = Batch(observation = obs, next_observation = next_obs, action = action_id, reward = reward, done = done)\n",
        "#     replay.add(batch)\n",
        "#     total_reward += reward\n",
        "#     # env.render()\n",
        "#     obs = next_obs\n",
        "\n",
        "#   return total_reward"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JzlY5o5ZRkUo",
        "outputId": "32c0d125-0983-4518-a30f-0f84fe5a9921"
      },
      "source": [
        "# obs = env.reset()\n",
        "# print(obs.shape)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(12,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pI1XflP5RNP0"
      },
      "source": [
        "# replay = TransitionBuffer(12)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WuosIm2DRuLw",
        "outputId": "380dd1f3-2f25-4fb0-fcc1-9f826d5471db"
      },
      "source": [
        "# run_one_episode(random_policy, env, replay)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "-5"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1cVWebTR5el",
        "outputId": "4b252ccb-3f99-4c94-f01f-4bb55d169d89"
      },
      "source": [
        "# returns = []\n",
        "# for episode in range(100):\n",
        "#   reward = run_one_episode(random_policy, env, replay)\n",
        "#   returns.append(reward)\n",
        "  \n",
        "# print(\"av. returns = \", np.mean(returns))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "av. returns =  -4.86\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRcLa7oVSyqb"
      },
      "source": [
        "# batch = replay.sample()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgIjlwwXV-gA"
      },
      "source": [
        "class Counter:\n",
        "\n",
        "    def __init__(self):\n",
        "        self.value = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUdjTRWbS4dL"
      },
      "source": [
        "class Actor:\n",
        "  def __init__(self, num_actions, q_net, replay, counter, eps_decay = 0.999999, eps_min=0.05):\n",
        "    self.eps_decay = eps_decay\n",
        "    self.eps_min = eps_min\n",
        "    self.eps = 1\n",
        "    self.num_actions = num_actions\n",
        "    self.q_net = q_net\n",
        "    self.replay = replay\n",
        "    self.ctr = counter\n",
        "\n",
        "  def observe(self, obs, act, rew, next_obs, done):\n",
        "    batch = Batch(\n",
        "      observation=self._concat_extras(obs),\n",
        "      next_observation=self._concat_extras(next_obs),\n",
        "      reward=rew,\n",
        "      action=act,\n",
        "      done=done\n",
        "    )\n",
        "    \n",
        "    self.replay.add(batch)\n",
        "\n",
        "  def _concat_extras(self, obs):\n",
        "    eps = [self.eps]\n",
        "    learn_step = [self.ctr.value / 1_000_000]\n",
        "    new_obs = np.concatenate([eps, learn_step, obs])\n",
        "    return new_obs\n",
        "    \n",
        "\n",
        "  def policy(self, obs):\n",
        "    if np.random.random() < self.eps:\n",
        "      action_id = np.random.randint(self.num_actions)\n",
        "    else: \n",
        "      obs = self._concat_extras(obs)\n",
        "      obs = tf.convert_to_tensor(obs, dtype = 'float32')\n",
        "      obs = tf.reshape(obs, (1,-1))\n",
        "      q_values = self.q_net(obs)\n",
        "      action_id = tf.argmax(q_values, axis = -1).numpy()[0]\n",
        "    action = ACTION_LOOKUP[action_id]\n",
        "    self.decrement_epsilon()\n",
        "    return action, action_id\n",
        "\n",
        "  def decrement_epsilon(self):\n",
        "    self.eps = max(self.eps_min, self.eps_decay*self.eps)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZY_WsopTJWh"
      },
      "source": [
        "# q_net = snt.nets.MLP((64, 6))\n",
        "# actor = Actor(6, q_net)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jr-2xistWDbz"
      },
      "source": [
        "def run_one_episode(actor, env, replay):\n",
        "  obs = env.reset()\n",
        "  done = False\n",
        "  total_reward = 0\n",
        "\n",
        "  while not done:\n",
        "    action, action_id = actor.policy(obs)\n",
        "    #print(actor.eps)\n",
        "    next_obs, reward, done, info = env.step(action)\n",
        "    batch = Batch(observation = obs, next_observation = next_obs, action = action_id, reward = reward, done = done)\n",
        "    replay.add(batch)\n",
        "    total_reward += reward\n",
        "    # env.render()\n",
        "    obs = next_obs\n",
        "\n",
        "  return total_reward"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xc8fyASnWT_n",
        "outputId": "711cbf10-81a3-4f0b-e001-bdbce18f0852"
      },
      "source": [
        "run_one_episode(actor, env, replay)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "-5"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ac4kybLzWaBs"
      },
      "source": [
        "class Learner:\n",
        "  def __init__(self, q_net, target_q_net, counter, lr = 5e-4, discount = 0.99, target_update_period = 200):\n",
        "    self.q_net = q_net\n",
        "    self.target_q_net = target_q_net\n",
        "    self.lr = lr\n",
        "    self.discount = discount\n",
        "    self.target_update_period = target_update_period\n",
        "    self.optimiser = snt.optimizers.Adam(lr)\n",
        "    self.counter = counter\n",
        "\n",
        "\n",
        "  @tf.function\n",
        "  def learn(self, batch):\n",
        "    obs = batch.observation\n",
        "    next_obs = batch.next_observation\n",
        "    action_id = batch.action\n",
        "    reward = batch.reward\n",
        "    done = batch.done\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "\n",
        "      q_values = self.q_net(obs)  #[B, Act]\n",
        "      selected_q_value = trfl.batched_index(q_values, action_id) #[B]\n",
        "\n",
        "      # Standard Q-learning\n",
        "      next_q_values = self.target_q_net(next_obs)\n",
        "      max_next_q_value = tf.reduce_max(next_q_values, axis=-1)\n",
        "\n",
        "      # Bellman target\n",
        "      target = reward + self.discount * (1 - done) * max_next_q_value\n",
        "\n",
        "      # Temporal difference\n",
        "      td_error = selected_q_value - target\n",
        "\n",
        "      # Mean-squared error\n",
        "      loss = tf.reduce_mean(td_error ** 2)\n",
        "\n",
        "\n",
        "    variables = self.q_net.trainable_variables #from sonnet\n",
        "    gradients = tape.gradient(loss, variables)\n",
        "    self.optimiser.apply(updates=gradients, parameters=variables)\n",
        "\n",
        "    return loss\n",
        "\n",
        "  def update_target_network(self):\n",
        "        \"\"\"Update target network.\"\"\"\n",
        "        if self.counter.value % self.target_update_period == 0:\n",
        "            online_variables = (*self.q_net.variables,)\n",
        "            target_variables = (*self.target_q_net.variables,)\n",
        "\n",
        "            for src, dest in zip(online_variables, target_variables):\n",
        "                dest.assign(src)\n",
        "\n",
        "        self.counter.value += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ba0pX0Hdmqm"
      },
      "source": [
        "\n",
        "target_q_net = copy.deepcopy(q_net)\n",
        "learner = Learner(q_net, target_q_net)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5S0kXdE7eKNI",
        "outputId": "d331b080-31d4-42b1-8b66-ae9152d5fdc2"
      },
      "source": [
        "batch = replay.sample()\n",
        "learner.learn(batch)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=0.07789205>"
            ]
          },
          "execution_count": 82,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOFLLc28eRW_"
      },
      "source": [
        "def train(learner, actor, replay_buffer, env, num_episodes = 10000, learner_steps_per_episode = 100):\n",
        "\n",
        "  episode_returns = []\n",
        "\n",
        "  for episode in range(num_episodes):\n",
        "\n",
        "    episode_return = run_one_episode(actor, env, replay_buffer)\n",
        "    episode_returns.append(episode_return)\n",
        "\n",
        "    losses = []\n",
        "    for learner_step in range(learner_steps_per_episode):\n",
        "      batch = replay.sample()\n",
        "      loss = learner.learn(batch)\n",
        "      losses.append(loss)\n",
        "    \n",
        "    if episode % 10 == 0:\n",
        "      print(f\"episode: {episode}  episode_return: {episode_return}  smoothed episode return: {np.mean(episode_returns[-50:])}  epsilon: {actor.eps} loss: {np.mean(losses)}\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "S6IBdEGQhPdS",
        "outputId": "1c679327-ba3a-449a-954c-17951b4f2815"
      },
      "source": [
        "LEARN_EVERY = 8\n",
        "\n",
        "q_net = snt.nets.MLP((128,128, 6))\n",
        "target_q_net = copy.deepcopy(q_net)\n",
        "\n",
        "actor = Actor(6, target_q_net, replay, Counter())\n",
        "learner = Learner(q_net, target_q_net, Counter())\n",
        "replay = TransitionBuffer(12, batch_size=256, buffer_size=1000000)\n",
        "\n",
        "env = gym.make(\"SlimeVolley-v0\")\n",
        "\n",
        "t = 0\n",
        "returns = []\n",
        "lens = []\n",
        "losses = []\n",
        "for e in range(10_000):\n",
        "    done = False\n",
        "    ep_return = 0\n",
        "    obs = env.reset()\n",
        "    ep_len = 0\n",
        "    while not done:\n",
        "\n",
        "        action, action_id = actor.policy(obs)\n",
        "\n",
        "        next_obs, reward, done, _ = env.step(action)\n",
        "\n",
        "        batch = Batch(\n",
        "            observation=obs,\n",
        "            next_observation=next_obs,\n",
        "            reward=reward,\n",
        "            done=done,\n",
        "            action=action_id,\n",
        "        )\n",
        "\n",
        "        replay.add(batch)\n",
        "\n",
        "        if t % LEARN_EVERY == 0 and replay.can_sample_batch():\n",
        "            batch = replay.sample()\n",
        "            loss = learner.learn(batch)\n",
        "            learner.update_target_network()\n",
        "            losses.append(loss)\n",
        "\n",
        "\n",
        "        obs = next_obs\n",
        "        ep_return += reward\n",
        "        t += 1\n",
        "        ep_len += 1\n",
        "\n",
        "    returns.append(ep_return)\n",
        "    lens.append(ep_len)\n",
        "\n",
        "    if e % 100 == 0:\n",
        "        print(f\"ep: {e}  t: {t} ep_return: {ep_return}  smoothed ep_return: {np.mean(returns[-100:])}   ep_len: {ep_len}   smoothed ep_len: {np.mean(lens[-100:])}  eps: {actor.eps} loss: {np.mean(losses[-10:])} \")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-f6b3908af9d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtarget_q_net\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_net\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mactor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mActor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_q_net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mlearner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLearner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_q_net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mreplay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTransitionBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'replay' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-wFvjzMkNkw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYBQkF3JhWqb",
        "outputId": "dfe1f908-2c75-4103-fd16-fa17f340b259"
      },
      "source": [
        "LEARN_EVERY = 8\n",
        "\n",
        "q_net1 = snt.nets.MLP((64,64, 6))\n",
        "target_q_net1 = copy.deepcopy(q_net1)\n",
        "counter1 = Counter()\n",
        "replay1 = TransitionBuffer(14, batch_size=256, buffer_size=10000)\n",
        "actor1 = Actor(6, target_q_net1, replay1, counter1, eps_decay=0.999999)\n",
        "learner1 = Learner(q_net1, target_q_net1, counter1)\n",
        "\n",
        "q_net2 = snt.nets.MLP((64,64, 6))\n",
        "target_q_net2 = copy.deepcopy(q_net2)\n",
        "replay2 = TransitionBuffer(14, batch_size=256, buffer_size=10000)\n",
        "counter2 = Counter()\n",
        "actor2 = Actor(6, target_q_net2, replay2, counter2, eps_decay=0.999999)\n",
        "learner2 = Learner(q_net2, target_q_net2, counter2)\n",
        "\n",
        "\n",
        "env = gym.make(\"SlimeVolley-v0\")\n",
        "\n",
        "#wandb.init(project = \"MultiSlime\", name = \"MultiSlime\")\n",
        "\n",
        "t = 0\n",
        "returns = []\n",
        "lens = []\n",
        "losses = []\n",
        "for e in range(5000):\n",
        "    done = False\n",
        "    ep_return = 0\n",
        "    obs1 = env.reset()\n",
        "    obs2 = obs1\n",
        "    ep_len = 0\n",
        "    while not done:\n",
        "\n",
        "        action1, action_id1 = actor1.policy(obs1)\n",
        "        action2, action_id2 = actor2.policy(obs2)\n",
        "\n",
        "        next_obs1, reward, done, info = env.step(action1, action2)\n",
        "        next_obs2 = info['otherObs']\n",
        "\n",
        "        actor1.observe(obs=obs1, act=action_id1, rew=min(reward, -reward), next_obs=next_obs1, done=done)\n",
        "\n",
        "        actor2.observe(obs=obs2, act=action_id2, rew=min(reward, -reward), next_obs=next_obs2, done=done)\n",
        "\n",
        "        if t % LEARN_EVERY == 0 and replay1.can_sample_batch() and replay2.can_sample_batch():\n",
        "            batch1 = replay1.sample()\n",
        "            batch2 = replay2.sample()\n",
        "\n",
        "            loss = learner1.learn(batch1)\n",
        "            loss = learner2.learn(batch2)\n",
        "\n",
        "            learner1.update_target_network()\n",
        "            learner2.update_target_network()\n",
        "\n",
        "            losses.append(loss)\n",
        "\n",
        "\n",
        "        obs1 = next_obs1\n",
        "        obs2 = next_obs2\n",
        "\n",
        "        ep_return += reward\n",
        "        t += 1\n",
        "        ep_len += 1\n",
        "\n",
        "    returns.append(ep_return)\n",
        "    lens.append(ep_len)\n",
        "    #wandb.log({'reward':np.mean(returns[-100:]), 'lengths': ep_len}, step = e)\n",
        "    if e % 25 == 0:\n",
        "        print(f\"ep: {e}  t: {t} ep_return: {ep_return}  smoothed ep_return: {np.mean(returns[-100:])}   ep_len: {ep_len}   smoothed ep_len: {np.mean(lens[-100:])}  eps: {actor1.eps} loss: {np.mean(losses[-10:])} learn steps: {learner1.counter.value}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep: 0  t: 521 ep_return: 4  smoothed ep_return: 4.0   ep_len: 521   smoothed ep_len: 521.0  eps: 0.9994791354365526 loss: 0.0371665395796299 learn steps: 34\n",
            "ep: 25  t: 16833 ep_return: 5  smoothed ep_return: 0.038461538461538464   ep_len: 391   smoothed ep_len: 647.4230769230769  eps: 0.9833078750639589 loss: 0.014271475374698639 learn steps: 2073\n",
            "ep: 50  t: 32873 ep_return: -1  smoothed ep_return: -0.47058823529411764   ep_len: 692   smoothed ep_len: 644.5686274509804  eps: 0.9676614288832533 loss: 0.015850482508540154 learn steps: 4078\n",
            "ep: 75  t: 47989 ep_return: -4  smoothed ep_return: -0.10526315789473684   ep_len: 538   smoothed ep_len: 631.4342105263158  eps: 0.9531442487352768 loss: 0.01636453904211521 learn steps: 5967\n",
            "ep: 100  t: 63198 ep_return: -2  smoothed ep_return: -0.07   ep_len: 694   smoothed ep_len: 626.77  eps: 0.9387575516197771 loss: 0.0200545284897089 learn steps: 7868\n",
            "ep: 125  t: 79204 ep_return: -2  smoothed ep_return: 0.08   ep_len: 607   smoothed ep_len: 623.71  eps: 0.9238514029381323 loss: 0.014311941340565681 learn steps: 9869\n",
            "ep: 150  t: 95822 ep_return: 2  smoothed ep_return: 0.29   ep_len: 678   smoothed ep_len: 629.49  eps: 0.9086256935206218 loss: 0.016640735790133476 learn steps: 11946\n",
            "ep: 175  t: 112336 ep_return: -3  smoothed ep_return: 0.12   ep_len: 564   smoothed ep_len: 643.47  eps: 0.893743858888489 loss: 0.013103184290230274 learn steps: 14010\n",
            "ep: 200  t: 128160 ep_return: -1  smoothed ep_return: 0.13   ep_len: 681   smoothed ep_len: 649.62  eps: 0.8797125574902627 loss: 0.017707161605358124 learn steps: 15988\n",
            "ep: 225  t: 143986 ep_return: -2  smoothed ep_return: 0.1   ep_len: 646   smoothed ep_len: 647.82  eps: 0.8658998082302088 loss: 0.015387965366244316 learn steps: 17967\n",
            "ep: 250  t: 159403 ep_return: 5  smoothed ep_return: 0.03   ep_len: 454   smoothed ep_len: 635.81  eps: 0.8526526027326841 loss: 0.01587503030896187 learn steps: 19894\n",
            "ep: 275  t: 175214 ep_return: 2  smoothed ep_return: -0.19   ep_len: 637   smoothed ep_len: 628.78  eps: 0.839277322656452 loss: 0.01358013041317463 learn steps: 21870\n",
            "ep: 300  t: 192048 ep_return: -5  smoothed ep_return: -0.26   ep_len: 456   smoothed ep_len: 638.88  eps: 0.8252671754626767 loss: 0.021329786628484726 learn steps: 23974\n",
            "ep: 325  t: 207535 ep_return: 4  smoothed ep_return: -0.15   ep_len: 521   smoothed ep_len: 635.49  eps: 0.8125847164825665 loss: 0.018267344683408737 learn steps: 25910\n",
            "ep: 350  t: 223888 ep_return: -1  smoothed ep_return: 0.34   ep_len: 751   smoothed ep_len: 644.85  eps: 0.7994045731841585 loss: 0.013858480378985405 learn steps: 27954\n",
            "ep: 375  t: 240493 ep_return: 2  smoothed ep_return: 0.81   ep_len: 731   smoothed ep_len: 652.79  eps: 0.7862400545617834 loss: 0.019643742591142654 learn steps: 30030\n",
            "ep: 400  t: 257104 ep_return: -1  smoothed ep_return: 0.69   ep_len: 790   smoothed ep_len: 650.56  eps: 0.7732876882399845 loss: 0.024115733802318573 learn steps: 32106\n",
            "ep: 425  t: 272620 ep_return: 2  smoothed ep_return: 0.59   ep_len: 754   smoothed ep_len: 650.85  eps: 0.7613819540560791 loss: 0.021949654445052147 learn steps: 34046\n",
            "ep: 450  t: 289254 ep_return: 1  smoothed ep_return: 0.13   ep_len: 704   smoothed ep_len: 653.66  eps: 0.7488218721559221 loss: 0.019889608025550842 learn steps: 36125\n",
            "ep: 475  t: 305007 ep_return: 4  smoothed ep_return: 0.09   ep_len: 570   smoothed ep_len: 645.14  eps: 0.7371181021264351 loss: 0.023727750405669212 learn steps: 38094\n",
            "ep: 500  t: 322622 ep_return: -2  smoothed ep_return: 0.09   ep_len: 648   smoothed ep_len: 655.18  eps: 0.7242474513776368 loss: 0.014090122655034065 learn steps: 40296\n",
            "ep: 525  t: 339294 ep_return: -4  smoothed ep_return: -0.03   ep_len: 478   smoothed ep_len: 666.74  eps: 0.7122728891962129 loss: 0.02036428079009056 learn steps: 42380\n",
            "ep: 550  t: 355713 ep_return: -1  smoothed ep_return: -0.03   ep_len: 727   smoothed ep_len: 664.59  eps: 0.7006735601020279 loss: 0.026434462517499924 learn steps: 44433\n",
            "ep: 575  t: 371705 ep_return: 2  smoothed ep_return: -0.18   ep_len: 673   smoothed ep_len: 666.98  eps: 0.6895575038607936 loss: 0.021091772243380547 learn steps: 46432\n",
            "ep: 600  t: 387276 ep_return: 4  smoothed ep_return: -0.09   ep_len: 564   smoothed ep_len: 646.54  eps: 0.6789035601780974 loss: 0.02931870147585869 learn steps: 48378\n",
            "ep: 625  t: 403713 ep_return: 1  smoothed ep_return: -0.18   ep_len: 826   smoothed ep_len: 644.19  eps: 0.6678356278161374 loss: 0.019544318318367004 learn steps: 50433\n",
            "ep: 650  t: 419197 ep_return: 1  smoothed ep_return: 0.02   ep_len: 728   smoothed ep_len: 634.84  eps: 0.6575745024682694 loss: 0.0258282870054245 learn steps: 52368\n",
            "ep: 675  t: 435685 ep_return: -3  smoothed ep_return: -0.12   ep_len: 573   smoothed ep_len: 639.8  eps: 0.646821301689413 loss: 0.02706245519220829 learn steps: 54429\n",
            "ep: 700  t: 452109 ep_return: -1  smoothed ep_return: -0.06   ep_len: 749   smoothed ep_len: 648.33  eps: 0.6362846670573056 loss: 0.012170108035206795 learn steps: 56482\n",
            "ep: 725  t: 468437 ep_return: -1  smoothed ep_return: -0.11   ep_len: 724   smoothed ep_len: 647.24  eps: 0.6259797640319071 loss: 0.02388215810060501 learn steps: 58523\n",
            "ep: 750  t: 484619 ep_return: 3  smoothed ep_return: -0.27   ep_len: 641   smoothed ep_len: 654.22  eps: 0.6159316728347272 loss: 0.030835136771202087 learn steps: 60546\n",
            "ep: 775  t: 501524 ep_return: -4  smoothed ep_return: -0.29   ep_len: 478   smoothed ep_len: 658.39  eps: 0.6056068591142705 loss: 0.029161851853132248 learn steps: 62659\n",
            "ep: 800  t: 517977 ep_return: 1  smoothed ep_return: -0.24   ep_len: 770   smoothed ep_len: 658.68  eps: 0.5957243261110398 loss: 0.025325950235128403 learn steps: 64716\n",
            "ep: 825  t: 533960 ep_return: -1  smoothed ep_return: 0.09   ep_len: 820   smoothed ep_len: 655.23  eps: 0.5862785465125396 loss: 0.017891326919198036 learn steps: 66713\n",
            "ep: 850  t: 550197 ep_return: 1  smoothed ep_return: 0.05   ep_len: 729   smoothed ep_len: 655.78  eps: 0.5768360037665364 loss: 0.02324574813246727 learn steps: 68743\n",
            "ep: 875  t: 565803 ep_return: 3  smoothed ep_return: 0.25   ep_len: 590   smoothed ep_len: 642.79  eps: 0.5679037760823064 loss: 0.03004273772239685 learn steps: 70694\n",
            "ep: 900  t: 582201 ep_return: -3  smoothed ep_return: 0.0   ep_len: 604   smoothed ep_len: 642.24  eps: 0.5586672228144423 loss: 0.02105761505663395 learn steps: 72744\n",
            "ep: 925  t: 598170 ep_return: -3  smoothed ep_return: -0.17   ep_len: 562   smoothed ep_len: 642.1  eps: 0.5498167164550007 loss: 0.023767730221152306 learn steps: 74740\n",
            "ep: 950  t: 613471 ep_return: -1  smoothed ep_return: -0.17   ep_len: 720   smoothed ep_len: 632.74  eps: 0.5414680014295254 loss: 0.029409075155854225 learn steps: 76652\n",
            "ep: 975  t: 628798 ep_return: -1  smoothed ep_return: -0.12   ep_len: 810   smoothed ep_len: 629.95  eps: 0.5332321935938298 loss: 0.02308371290564537 learn steps: 78568\n",
            "ep: 1000  t: 644801 ep_return: 2  smoothed ep_return: 0.16   ep_len: 723   smoothed ep_len: 626.0  eps: 0.5247667911467805 loss: 0.024429764598608017 learn steps: 80569\n",
            "ep: 1025  t: 661317 ep_return: -2  smoothed ep_return: 0.09   ep_len: 788   smoothed ep_len: 631.47  eps: 0.5161709186376674 loss: 0.019179293885827065 learn steps: 82633\n",
            "ep: 1050  t: 678257 ep_return: -2  smoothed ep_return: 0.27   ep_len: 716   smoothed ep_len: 647.86  eps: 0.5075006236762379 loss: 0.020869331434369087 learn steps: 84751\n",
            "ep: 1075  t: 694807 ep_return: -2  smoothed ep_return: 0.13   ep_len: 684   smoothed ep_len: 660.09  eps: 0.49917060522546036 loss: 0.027183253318071365 learn steps: 86819\n",
            "ep: 1100  t: 711853 ep_return: -2  smoothed ep_return: 0.19   ep_len: 742   smoothed ep_len: 670.52  eps: 0.49073384962354827 loss: 0.02452992834150791 learn steps: 88950\n",
            "ep: 1125  t: 727910 ep_return: -3  smoothed ep_return: 0.39   ep_len: 562   smoothed ep_len: 665.93  eps: 0.4829170573561036 loss: 0.026763681322336197 learn steps: 90957\n",
            "ep: 1150  t: 744813 ep_return: -3  smoothed ep_return: 0.19   ep_len: 570   smoothed ep_len: 665.56  eps: 0.47482290671753874 loss: 0.02157020755112171 learn steps: 93070\n",
            "ep: 1175  t: 760604 ep_return: 4  smoothed ep_return: 0.49   ep_len: 542   smoothed ep_len: 657.97  eps: 0.46738386401951326 loss: 0.022872015833854675 learn steps: 95044\n",
            "ep: 1200  t: 776595 ep_return: 1  smoothed ep_return: 0.24   ep_len: 707   smoothed ep_len: 647.42  eps: 0.45996936556240386 loss: 0.02638290263712406 learn steps: 97043\n",
            "ep: 1225  t: 793383 ep_return: -3  smoothed ep_return: -0.07   ep_len: 633   smoothed ep_len: 654.73  eps: 0.452311853031288 loss: 0.02739725075662136 learn steps: 99141\n",
            "ep: 1250  t: 810274 ep_return: -4  smoothed ep_return: 0.11   ep_len: 463   smoothed ep_len: 654.61  eps: 0.4447360116208097 loss: 0.021822668612003326 learn steps: 101253\n",
            "ep: 1275  t: 826554 ep_return: 3  smoothed ep_return: -0.18   ep_len: 631   smoothed ep_len: 659.5  eps: 0.43755432332130645 loss: 0.028056547045707703 learn steps: 103288\n",
            "ep: 1300  t: 842005 ep_return: -3  smoothed ep_return: -0.17   ep_len: 585   smoothed ep_len: 654.1  eps: 0.43084562959581296 loss: 0.02364599145948887 learn steps: 105219\n",
            "ep: 1325  t: 858083 ep_return: -3  smoothed ep_return: 0.04   ep_len: 653   smoothed ep_len: 647.0  eps: 0.4239738801504568 loss: 0.0252400990575552 learn steps: 107229\n",
            "ep: 1350  t: 874984 ep_return: -2  smoothed ep_return: 0.01   ep_len: 700   smoothed ep_len: 647.1  eps: 0.41686850713688833 loss: 0.016789134591817856 learn steps: 109341\n",
            "ep: 1375  t: 891175 ep_return: 2  smoothed ep_return: -0.1   ep_len: 670   smoothed ep_len: 646.21  eps: 0.4101733328338754 loss: 0.026096586138010025 learn steps: 111365\n",
            "ep: 1400  t: 907661 ep_return: 1  smoothed ep_return: -0.01   ep_len: 755   smoothed ep_len: 656.56  eps: 0.40346664702558116 loss: 0.018365290015935898 learn steps: 113426\n",
            "ep: 1425  t: 923427 ep_return: 4  smoothed ep_return: 0.02   ep_len: 572   smoothed ep_len: 653.44  eps: 0.39715547044636135 loss: 0.017810916528105736 learn steps: 115397\n",
            "ep: 1450  t: 939765 ep_return: -4  smoothed ep_return: -0.12   ep_len: 486   smoothed ep_len: 647.81  eps: 0.39071946008392167 loss: 0.023622041568160057 learn steps: 117439\n",
            "ep: 1475  t: 954366 ep_return: 4  smoothed ep_return: -0.19   ep_len: 524   smoothed ep_len: 631.91  eps: 0.38505600905482673 loss: 0.020079707726836205 learn steps: 119264\n",
            "ep: 1500  t: 970026 ep_return: 5  smoothed ep_return: -0.25   ep_len: 395   smoothed ep_len: 623.65  eps: 0.37907299820645896 loss: 0.026860784739255905 learn steps: 121222\n",
            "ep: 1525  t: 986880 ep_return: 3  smoothed ep_return: -0.32   ep_len: 693   smoothed ep_len: 634.53  eps: 0.3727376367840413 loss: 0.021992921829223633 learn steps: 123328\n",
            "ep: 1550  t: 1002155 ep_return: 2  smoothed ep_return: -0.12   ep_len: 762   smoothed ep_len: 623.9  eps: 0.36708733063313886 loss: 0.026445085182785988 learn steps: 125238\n",
            "ep: 1575  t: 1018952 ep_return: 1  smoothed ep_return: -0.15   ep_len: 783   smoothed ep_len: 645.86  eps: 0.3609728578432486 loss: 0.01632394641637802 learn steps: 127337\n",
            "ep: 1600  t: 1035705 ep_return: -1  smoothed ep_return: -0.08   ep_len: 836   smoothed ep_len: 656.79  eps: 0.35497585074797555 loss: 0.01893046125769615 learn steps: 129432\n",
            "ep: 1625  t: 1051113 ep_return: -1  smoothed ep_return: -0.15   ep_len: 831   smoothed ep_len: 642.33  eps: 0.34954830134389864 loss: 0.02294115535914898 learn steps: 131358\n",
            "ep: 1650  t: 1067000 ep_return: -5  smoothed ep_return: -0.35   ep_len: 468   smoothed ep_len: 648.45  eps: 0.3440389044984969 loss: 0.0226286593824625 learn steps: 133343\n",
            "ep: 1675  t: 1083785 ep_return: 1  smoothed ep_return: -0.05   ep_len: 775   smoothed ep_len: 648.33  eps: 0.3383124027354717 loss: 0.01891511119902134 learn steps: 135442\n",
            "ep: 1700  t: 1099761 ep_return: 2  smoothed ep_return: -0.05   ep_len: 697   smoothed ep_len: 640.56  eps: 0.33295046630112596 loss: 0.018058860674500465 learn steps: 137439\n",
            "ep: 1725  t: 1116805 ep_return: -2  smoothed ep_return: 0.11   ep_len: 719   smoothed ep_len: 656.92  eps: 0.32732374288892246 loss: 0.0236800666898489 learn steps: 139569\n",
            "ep: 1750  t: 1132187 ep_return: -2  smoothed ep_return: 0.0   ep_len: 619   smoothed ep_len: 651.87  eps: 0.3223273721785124 loss: 0.026267165318131447 learn steps: 141492\n",
            "ep: 1775  t: 1148081 ep_return: 4  smoothed ep_return: -0.12   ep_len: 502   smoothed ep_len: 642.96  eps: 0.3172447966076981 loss: 0.020504534244537354 learn steps: 143479\n",
            "ep: 1800  t: 1165092 ep_return: -3  smoothed ep_return: -0.15   ep_len: 646   smoothed ep_len: 653.31  eps: 0.3118937847646449 loss: 0.017467821016907692 learn steps: 145605\n",
            "ep: 1825  t: 1181880 ep_return: -1  smoothed ep_return: -0.12   ep_len: 734   smoothed ep_len: 650.75  eps: 0.30670141600266937 loss: 0.023642629384994507 learn steps: 147703\n",
            "ep: 1850  t: 1198028 ep_return: 1  smoothed ep_return: 0.02   ep_len: 700   smoothed ep_len: 658.41  eps: 0.3017885721366981 loss: 0.020189132541418076 learn steps: 149722\n",
            "ep: 1875  t: 1214910 ep_return: -4  smoothed ep_return: -0.11   ep_len: 475   smoothed ep_len: 668.29  eps: 0.29673653913239706 loss: 0.022454869002103806 learn steps: 151832\n",
            "ep: 1900  t: 1230350 ep_return: -3  smoothed ep_return: 0.02   ep_len: 558   smoothed ep_len: 652.58  eps: 0.29219011342093143 loss: 0.019325535744428635 learn steps: 153762\n",
            "ep: 1925  t: 1245506 ep_return: 2  smoothed ep_return: -0.08   ep_len: 695   smoothed ep_len: 636.26  eps: 0.2877950676509291 loss: 0.019923929125070572 learn steps: 155657\n",
            "ep: 1950  t: 1261871 ep_return: -3  smoothed ep_return: -0.23   ep_len: 552   smoothed ep_len: 638.43  eps: 0.2831236273489474 loss: 0.026347562670707703 learn steps: 157702\n",
            "ep: 1975  t: 1278175 ep_return: 4  smoothed ep_return: 0.0   ep_len: 539   smoothed ep_len: 632.65  eps: 0.27854500380225933 loss: 0.020585868507623672 learn steps: 159740\n",
            "ep: 2000  t: 1294551 ep_return: 1  smoothed ep_return: -0.4   ep_len: 812   smoothed ep_len: 642.01  eps: 0.27402069470843515 loss: 0.02230820804834366 learn steps: 161787\n",
            "ep: 2025  t: 1310651 ep_return: 3  smoothed ep_return: -0.32   ep_len: 600   smoothed ep_len: 651.45  eps: 0.26964428397546 loss: 0.019537489861249924 learn steps: 163800\n",
            "ep: 2050  t: 1327973 ep_return: -4  smoothed ep_return: -0.1   ep_len: 659   smoothed ep_len: 661.02  eps: 0.265013724432633 loss: 0.019504379481077194 learn steps: 165965\n",
            "ep: 2075  t: 1342807 ep_return: 3  smoothed ep_return: -0.29   ep_len: 625   smoothed ep_len: 646.32  eps: 0.2611115230762443 loss: 0.019467707723379135 learn steps: 167819\n",
            "ep: 2100  t: 1357131 ep_return: -3  smoothed ep_return: -0.01   ep_len: 621   smoothed ep_len: 625.8  eps: 0.2573980193699913 loss: 0.019081084057688713 learn steps: 169610\n",
            "ep: 2125  t: 1373467 ep_return: 4  smoothed ep_return: -0.23   ep_len: 545   smoothed ep_len: 628.16  eps: 0.25322732224489686 loss: 0.01592155732214451 learn steps: 171652\n",
            "ep: 2150  t: 1389457 ep_return: 2  smoothed ep_return: -0.4   ep_len: 662   smoothed ep_len: 614.84  eps: 0.2492104161048127 loss: 0.016113661229610443 learn steps: 173651\n",
            "ep: 2175  t: 1405664 ep_return: -5  smoothed ep_return: -0.4   ep_len: 432   smoothed ep_len: 628.57  eps: 0.24520401445882556 loss: 0.01745935156941414 learn steps: 175676\n",
            "ep: 2200  t: 1421524 ep_return: -2  smoothed ep_return: -0.46   ep_len: 657   smoothed ep_len: 643.93  eps: 0.2413457537428913 loss: 0.022606676444411278 learn steps: 177659\n",
            "ep: 2225  t: 1437605 ep_return: -3  smoothed ep_return: -0.35   ep_len: 547   smoothed ep_len: 641.38  eps: 0.2374957099962297 loss: 0.024154793471097946 learn steps: 179669\n",
            "ep: 2250  t: 1453110 ep_return: -3  smoothed ep_return: -0.49   ep_len: 586   smoothed ep_len: 636.53  eps: 0.23384173780755643 loss: 0.02040167897939682 learn steps: 181607\n",
            "ep: 2275  t: 1467721 ep_return: 2  smoothed ep_return: -0.14   ep_len: 648   smoothed ep_len: 620.57  eps: 0.23044991379152854 loss: 0.026346072554588318 learn steps: 183434\n",
            "ep: 2300  t: 1483735 ep_return: -1  smoothed ep_return: -0.23   ep_len: 813   smoothed ep_len: 622.11  eps: 0.22678887918406554 loss: 0.02383871003985405 learn steps: 185435\n",
            "ep: 2325  t: 1499571 ep_return: 4  smoothed ep_return: -0.12   ep_len: 518   smoothed ep_len: 619.66  eps: 0.22322573614139313 loss: 0.020482061430811882 learn steps: 187415\n",
            "ep: 2350  t: 1516025 ep_return: 1  smoothed ep_return: 0.12   ep_len: 705   smoothed ep_len: 629.15  eps: 0.2195828304305574 loss: 0.020609285682439804 learn steps: 189472\n",
            "ep: 2375  t: 1531227 ep_return: -2  smoothed ep_return: -0.22   ep_len: 630   smoothed ep_len: 635.06  eps: 0.21626997539701268 loss: 0.024715233594179153 learn steps: 191372\n",
            "ep: 2400  t: 1547809 ep_return: 1  smoothed ep_return: -0.12   ep_len: 752   smoothed ep_len: 640.74  eps: 0.21271335432638255 loss: 0.025048688054084778 learn steps: 193445\n",
            "ep: 2425  t: 1563988 ep_return: -3  smoothed ep_return: -0.36   ep_len: 583   smoothed ep_len: 644.17  eps: 0.20929955366627365 loss: 0.015596511773765087 learn steps: 195467\n",
            "ep: 2450  t: 1579970 ep_return: 2  smoothed ep_return: -0.58   ep_len: 654   smoothed ep_len: 639.45  eps: 0.2059811148189937 loss: 0.016036996617913246 learn steps: 197465\n",
            "ep: 2475  t: 1595338 ep_return: -2  smoothed ep_return: -0.44   ep_len: 718   smoothed ep_len: 641.11  eps: 0.20283979520064646 loss: 0.02388002909719944 learn steps: 199386\n",
            "ep: 2500  t: 1611110 ep_return: 3  smoothed ep_return: -0.26   ep_len: 529   smoothed ep_len: 633.01  eps: 0.19966570106760495 loss: 0.017423346638679504 learn steps: 201357\n",
            "ep: 2525  t: 1627041 ep_return: -1  smoothed ep_return: -0.04   ep_len: 778   smoothed ep_len: 630.53  eps: 0.19651002845752 loss: 0.024471888318657875 learn steps: 203349\n",
            "ep: 2550  t: 1642787 ep_return: -3  smoothed ep_return: 0.19   ep_len: 574   smoothed ep_len: 628.17  eps: 0.19344001367124267 loss: 0.016958553344011307 learn steps: 205317\n",
            "ep: 2575  t: 1658600 ep_return: 1  smoothed ep_return: 0.39   ep_len: 799   smoothed ep_len: 632.62  eps: 0.19040520318455453 loss: 0.017015185207128525 learn steps: 207293\n",
            "ep: 2600  t: 1675229 ep_return: -3  smoothed ep_return: 0.18   ep_len: 555   smoothed ep_len: 641.19  eps: 0.1872651339546041 loss: 0.021426919847726822 learn steps: 209372\n",
            "ep: 2625  t: 1690757 ep_return: 3  smoothed ep_return: 0.4   ep_len: 582   smoothed ep_len: 637.16  eps: 0.18437973968954302 loss: 0.018223213031888008 learn steps: 211313\n",
            "ep: 2650  t: 1706186 ep_return: 3  smoothed ep_return: 0.39   ep_len: 577   smoothed ep_len: 633.99  eps: 0.18155677702109366 loss: 0.020025860518217087 learn steps: 213242\n",
            "ep: 2675  t: 1723527 ep_return: 2  smoothed ep_return: 0.36   ep_len: 638   smoothed ep_len: 649.27  eps: 0.1784355402884647 loss: 0.018865933641791344 learn steps: 215409\n",
            "ep: 2700  t: 1739417 ep_return: 4  smoothed ep_return: 0.64   ep_len: 534   smoothed ep_len: 641.88  eps: 0.17562260609564947 loss: 0.018883446231484413 learn steps: 217396\n",
            "ep: 2725  t: 1756338 ep_return: 1  smoothed ep_return: 0.22   ep_len: 719   smoothed ep_len: 655.81  eps: 0.17267589545808823 loss: 0.017063995823264122 learn steps: 219511\n",
            "ep: 2750  t: 1772190 ep_return: 1  smoothed ep_return: 0.01   ep_len: 776   smoothed ep_len: 660.04  eps: 0.16996021713915613 loss: 0.019712449982762337 learn steps: 221492\n",
            "ep: 2775  t: 1788158 ep_return: 1  smoothed ep_return: -0.18   ep_len: 782   smoothed ep_len: 646.31  eps: 0.16726784415904267 loss: 0.025979459285736084 learn steps: 223488\n",
            "ep: 2800  t: 1804260 ep_return: -1  smoothed ep_return: -0.55   ep_len: 740   smoothed ep_len: 648.43  eps: 0.16459606422348036 loss: 0.01611362025141716 learn steps: 225501\n",
            "ep: 2825  t: 1820067 ep_return: 4  smoothed ep_return: -0.27   ep_len: 485   smoothed ep_len: 637.29  eps: 0.1620147481247281 loss: 0.02197958528995514 learn steps: 227477\n",
            "ep: 2850  t: 1836373 ep_return: 2  smoothed ep_return: 0.15   ep_len: 689   smoothed ep_len: 641.83  eps: 0.15939435644504676 loss: 0.024105330929160118 learn steps: 229515\n",
            "ep: 2875  t: 1852353 ep_return: -2  smoothed ep_return: -0.07   ep_len: 644   smoothed ep_len: 641.95  eps: 0.15686747690494834 loss: 0.023505505174398422 learn steps: 231513\n",
            "ep: 2900  t: 1868331 ep_return: 1  smoothed ep_return: -0.11   ep_len: 826   smoothed ep_len: 640.71  eps: 0.15438096476077262 loss: 0.01849181577563286 learn steps: 233510\n",
            "ep: 2925  t: 1884498 ep_return: -1  smoothed ep_return: -0.21   ep_len: 749   smoothed ep_len: 644.31  eps: 0.1519051536103548 loss: 0.026083851233124733 learn steps: 235531\n",
            "ep: 2950  t: 1900865 ep_return: -5  smoothed ep_return: -0.44   ep_len: 446   smoothed ep_len: 644.92  eps: 0.14943915626620305 loss: 0.017863616347312927 learn steps: 237577\n",
            "ep: 2975  t: 1916168 ep_return: -5  smoothed ep_return: -0.25   ep_len: 428   smoothed ep_len: 638.15  eps: 0.1471696967810116 loss: 0.017729884013533592 learn steps: 239489\n",
            "ep: 3000  t: 1933752 ep_return: -2  smoothed ep_return: 0.09   ep_len: 664   smoothed ep_len: 654.21  eps: 0.14460448300571815 loss: 0.02390601858496666 learn steps: 241687\n",
            "ep: 3025  t: 1948893 ep_return: -1  smoothed ep_return: 0.34   ep_len: 758   smoothed ep_len: 643.95  eps: 0.14243151739070933 loss: 0.017273221164941788 learn steps: 243580\n",
            "ep: 3050  t: 1964394 ep_return: -3  smoothed ep_return: 0.37   ep_len: 584   smoothed ep_len: 635.29  eps: 0.1402407090713626 loss: 0.019527198746800423 learn steps: 245518\n",
            "ep: 3075  t: 1980802 ep_return: 2  smoothed ep_return: 0.39   ep_len: 654   smoothed ep_len: 646.34  eps: 0.13795841353187666 loss: 0.018868714570999146 learn steps: 247569\n",
            "ep: 3100  t: 1995392 ep_return: 5  smoothed ep_return: 0.28   ep_len: 406   smoothed ep_len: 616.4  eps: 0.13596021160833374 loss: 0.020841700956225395 learn steps: 249392\n",
            "ep: 3125  t: 2011319 ep_return: -3  smoothed ep_return: 0.01   ep_len: 629   smoothed ep_len: 624.26  eps: 0.13381192553269405 loss: 0.017386816442012787 learn steps: 251383\n",
            "ep: 3150  t: 2026640 ep_return: -5  smoothed ep_return: -0.19   ep_len: 448   smoothed ep_len: 622.46  eps: 0.1317774171527967 loss: 0.019134176895022392 learn steps: 253298\n",
            "ep: 3175  t: 2043553 ep_return: 1  smoothed ep_return: -0.07   ep_len: 726   smoothed ep_len: 627.51  eps: 0.12956740622962706 loss: 0.02117593213915825 learn steps: 255413\n",
            "ep: 3200  t: 2059833 ep_return: 3  smoothed ep_return: -0.18   ep_len: 597   smoothed ep_len: 644.41  eps: 0.12747512518873386 loss: 0.019494207575917244 learn steps: 257448\n",
            "ep: 3225  t: 2076648 ep_return: 1  smoothed ep_return: -0.2   ep_len: 745   smoothed ep_len: 653.29  eps: 0.12534955074558315 loss: 0.02176523022353649 learn steps: 259549\n",
            "ep: 3250  t: 2093003 ep_return: 2  smoothed ep_return: 0.07   ep_len: 762   smoothed ep_len: 663.63  eps: 0.12331613143851249 loss: 0.015483299270272255 learn steps: 261594\n",
            "ep: 3275  t: 2108645 ep_return: -3  smoothed ep_return: 0.02   ep_len: 589   smoothed ep_len: 650.92  eps: 0.1214022272215426 loss: 0.020070169121026993 learn steps: 263549\n",
            "ep: 3300  t: 2125232 ep_return: 1  smoothed ep_return: -0.12   ep_len: 800   smoothed ep_len: 653.99  eps: 0.119405136142758 loss: 0.022594116628170013 learn steps: 265622\n",
            "ep: 3325  t: 2141225 ep_return: -2  smoothed ep_return: 0.02   ep_len: 713   smoothed ep_len: 645.77  eps: 0.11751067826515577 loss: 0.018641455098986626 learn steps: 267622\n",
            "ep: 3350  t: 2156871 ep_return: -1  smoothed ep_return: 0.08   ep_len: 780   smoothed ep_len: 638.68  eps: 0.11568641371685068 loss: 0.018891818821430206 learn steps: 269577\n",
            "ep: 3375  t: 2173274 ep_return: 3  smoothed ep_return: 0.2   ep_len: 579   smoothed ep_len: 646.29  eps: 0.11380428699385489 loss: 0.017450930550694466 learn steps: 271628\n",
            "ep: 3400  t: 2188676 ep_return: -3  smoothed ep_return: 0.5   ep_len: 588   smoothed ep_len: 634.44  eps: 0.11206490188541104 loss: 0.021391820162534714 learn steps: 273553\n",
            "ep: 3425  t: 2204852 ep_return: -3  smoothed ep_return: 0.46   ep_len: 543   smoothed ep_len: 636.27  eps: 0.11026672202171503 loss: 0.018969187512993813 learn steps: 275575\n",
            "ep: 3450  t: 2220555 ep_return: -1  smoothed ep_return: 0.53   ep_len: 754   smoothed ep_len: 636.84  eps: 0.10854872696734 loss: 0.017438432201743126 learn steps: 277538\n",
            "ep: 3475  t: 2236689 ep_return: -2  smoothed ep_return: 0.25   ep_len: 758   smoothed ep_len: 634.15  eps: 0.10681145321024148 loss: 0.02085542120039463 learn steps: 279555\n",
            "ep: 3500  t: 2252532 ep_return: 3  smoothed ep_return: 0.29   ep_len: 534   smoothed ep_len: 638.56  eps: 0.10513257288458497 loss: 0.020748239010572433 learn steps: 281535\n",
            "ep: 3525  t: 2268661 ep_return: 4  smoothed ep_return: 0.12   ep_len: 486   smoothed ep_len: 638.09  eps: 0.10345049039493304 loss: 0.01731453649699688 learn steps: 283551\n",
            "ep: 3550  t: 2283817 ep_return: -4  smoothed ep_return: 0.26   ep_len: 544   smoothed ep_len: 632.62  eps: 0.10189441570475317 loss: 0.022584307938814163 learn steps: 285446\n",
            "ep: 3575  t: 2300147 ep_return: -4  smoothed ep_return: 0.39   ep_len: 583   smoothed ep_len: 634.58  eps: 0.10024399146123951 loss: 0.023783858865499496 learn steps: 287487\n",
            "ep: 3600  t: 2317140 ep_return: -3  smoothed ep_return: 0.37   ep_len: 551   smoothed ep_len: 646.08  eps: 0.09855493617243738 loss: 0.021336430683732033 learn steps: 289611\n",
            "ep: 3625  t: 2332817 ep_return: 1  smoothed ep_return: 0.27   ep_len: 756   smoothed ep_len: 641.56  eps: 0.09702193747854454 loss: 0.013909375295042992 learn steps: 291571\n",
            "ep: 3650  t: 2348668 ep_return: 1  smoothed ep_return: -0.41   ep_len: 812   smoothed ep_len: 648.51  eps: 0.0954961664293408 loss: 0.021898772567510605 learn steps: 293552\n",
            "ep: 3675  t: 2366089 ep_return: 4  smoothed ep_return: -0.21   ep_len: 486   smoothed ep_len: 659.42  eps: 0.09384693423676231 loss: 0.02285059168934822 learn steps: 295730\n",
            "ep: 3700  t: 2382067 ep_return: 2  smoothed ep_return: -0.31   ep_len: 708   smoothed ep_len: 649.27  eps: 0.09235936303157971 loss: 0.017847076058387756 learn steps: 297727\n",
            "ep: 3725  t: 2399220 ep_return: -1  smoothed ep_return: 0.13   ep_len: 731   smoothed ep_len: 664.03  eps: 0.09078863197920498 loss: 0.018225103616714478 learn steps: 299871\n",
            "ep: 3750  t: 2415485 ep_return: 2  smoothed ep_return: 0.61   ep_len: 665   smoothed ep_len: 668.17  eps: 0.08932389838478536 loss: 0.02298346720635891 learn steps: 301904\n",
            "ep: 3775  t: 2430639 ep_return: -2  smoothed ep_return: 0.21   ep_len: 687   smoothed ep_len: 645.5  eps: 0.08798048808548213 loss: 0.017549199983477592 learn steps: 303798\n",
            "ep: 3800  t: 2446459 ep_return: -2  smoothed ep_return: 0.21   ep_len: 625   smoothed ep_len: 643.92  eps: 0.08659958779477608 loss: 0.020366303622722626 learn steps: 305776\n",
            "ep: 3825  t: 2462445 ep_return: 3  smoothed ep_return: -0.09   ep_len: 562   smoothed ep_len: 632.25  eps: 0.08522621273174824 loss: 0.020121034234762192 learn steps: 307774\n",
            "ep: 3850  t: 2478826 ep_return: -3  smoothed ep_return: -0.09   ep_len: 639   smoothed ep_len: 633.41  eps: 0.08384149395192557 loss: 0.019127506762742996 learn steps: 309822\n",
            "ep: 3875  t: 2494714 ep_return: -5  smoothed ep_return: 0.09   ep_len: 446   smoothed ep_len: 640.75  eps: 0.08251994581322152 loss: 0.01908065751194954 learn steps: 311808\n",
            "ep: 3900  t: 2509166 ep_return: 2  smoothed ep_return: 0.2   ep_len: 687   smoothed ep_len: 627.07  eps: 0.08133594317489208 loss: 0.020266758278012276 learn steps: 313614\n",
            "ep: 3925  t: 2524540 ep_return: -2  smoothed ep_return: 0.0   ep_len: 705   smoothed ep_len: 620.95  eps: 0.08009504697455219 loss: 0.0221867598593235 learn steps: 315536\n",
            "ep: 3950  t: 2540781 ep_return: -2  smoothed ep_return: -0.26   ep_len: 710   smoothed ep_len: 619.55  eps: 0.07880472906022638 loss: 0.02251516282558441 learn steps: 317566\n",
            "ep: 3975  t: 2557878 ep_return: 1  smoothed ep_return: -0.41   ep_len: 814   smoothed ep_len: 631.64  eps: 0.07746885618906633 loss: 0.022922229021787643 learn steps: 319703\n",
            "ep: 4000  t: 2574572 ep_return: -3  smoothed ep_return: -0.44   ep_len: 589   smoothed ep_len: 654.06  eps: 0.07618632553148647 loss: 0.01785547472536564 learn steps: 321790\n",
            "ep: 4025  t: 2590819 ep_return: 1  smoothed ep_return: -0.15   ep_len: 729   smoothed ep_len: 662.79  eps: 0.07495852671819012 loss: 0.017146850004792213 learn steps: 323821\n",
            "ep: 4050  t: 2606090 ep_return: -2  smoothed ep_return: 0.23   ep_len: 730   smoothed ep_len: 653.09  eps: 0.07382253046448593 loss: 0.01929274946451187 learn steps: 325730\n",
            "ep: 4075  t: 2621519 ep_return: 3  smoothed ep_return: 0.47   ep_len: 626   smoothed ep_len: 636.41  eps: 0.07269226393985267 loss: 0.018347563222050667 learn steps: 327658\n",
            "ep: 4100  t: 2637760 ep_return: 1  smoothed ep_return: 0.43   ep_len: 815   smoothed ep_len: 631.88  eps: 0.07152120363166405 loss: 0.018642805516719818 learn steps: 329688\n",
            "ep: 4125  t: 2654257 ep_return: -2  smoothed ep_return: 0.32   ep_len: 726   smoothed ep_len: 634.38  eps: 0.07035099674106092 loss: 0.022451505064964294 learn steps: 331751\n",
            "ep: 4150  t: 2671010 ep_return: -1  smoothed ep_return: 0.06   ep_len: 719   smoothed ep_len: 649.2  eps: 0.06918222347335251 loss: 0.020766135305166245 learn steps: 333845\n",
            "ep: 4175  t: 2686939 ep_return: -1  smoothed ep_return: -0.06   ep_len: 737   smoothed ep_len: 654.2  eps: 0.0680889497838298 loss: 0.02244780771434307 learn steps: 335836\n",
            "ep: 4200  t: 2702981 ep_return: -3  smoothed ep_return: 0.0   ep_len: 649   smoothed ep_len: 652.21  eps: 0.067005380853539 loss: 0.016385450959205627 learn steps: 337841\n",
            "ep: 4225  t: 2719478 ep_return: -3  smoothed ep_return: 0.15   ep_len: 639   smoothed ep_len: 652.21  eps: 0.06590906040029097 loss: 0.019400054588913918 learn steps: 339903\n",
            "ep: 4250  t: 2736246 ep_return: 1  smoothed ep_return: 0.2   ep_len: 759   smoothed ep_len: 652.36  eps: 0.06481311084706927 loss: 0.022835785523056984 learn steps: 341999\n",
            "ep: 4275  t: 2752419 ep_return: -3  smoothed ep_return: 0.11   ep_len: 613   smoothed ep_len: 654.8  eps: 0.06377331882800266 loss: 0.017427612096071243 learn steps: 344021\n",
            "ep: 4300  t: 2769102 ep_return: 2  smoothed ep_return: 0.06   ep_len: 655   smoothed ep_len: 661.21  eps: 0.06271821365374751 loss: 0.022802267223596573 learn steps: 346106\n",
            "ep: 4325  t: 2785920 ep_return: 4  smoothed ep_return: 0.05   ep_len: 540   smoothed ep_len: 664.42  eps: 0.06167223847277517 loss: 0.01525080669671297 learn steps: 348208\n",
            "ep: 4350  t: 2802030 ep_return: -1  smoothed ep_return: -0.05   ep_len: 703   smoothed ep_len: 657.84  eps: 0.06068665838152002 loss: 0.01871528849005699 learn steps: 350222\n",
            "ep: 4375  t: 2817427 ep_return: 1  smoothed ep_return: -0.14   ep_len: 726   smoothed ep_len: 650.08  eps: 0.059759422085477666 loss: 0.016750093549489975 learn steps: 352147\n",
            "ep: 4400  t: 2833084 ep_return: -1  smoothed ep_return: -0.34   ep_len: 815   smoothed ep_len: 639.82  eps: 0.0588310550361716 loss: 0.017731722444295883 learn steps: 354104\n",
            "ep: 4425  t: 2848594 ep_return: -3  smoothed ep_return: -0.54   ep_len: 575   smoothed ep_len: 626.74  eps: 0.05792562468301224 loss: 0.02047293819487095 learn steps: 356043\n",
            "ep: 4450  t: 2864517 ep_return: 1  smoothed ep_return: -0.64   ep_len: 792   smoothed ep_len: 624.87  eps: 0.05701057897351735 loss: 0.022099994122982025 learn steps: 358033\n",
            "ep: 4475  t: 2880877 ep_return: 1  smoothed ep_return: -0.51   ep_len: 729   smoothed ep_len: 634.5  eps: 0.056085473435825164 loss: 0.02106744609773159 learn steps: 360078\n",
            "ep: 4500  t: 2896340 ep_return: -2  smoothed ep_return: -0.26   ep_len: 736   smoothed ep_len: 632.56  eps: 0.05522489404661791 loss: 0.019034160301089287 learn steps: 362011\n",
            "ep: 4525  t: 2911516 ep_return: -1  smoothed ep_return: -0.16   ep_len: 761   smoothed ep_len: 629.22  eps: 0.05439312804277962 loss: 0.019554048776626587 learn steps: 363908\n",
            "ep: 4550  t: 2928340 ep_return: 2  smoothed ep_return: 0.06   ep_len: 629   smoothed ep_len: 638.23  eps: 0.05348567252295461 loss: 0.02563909813761711 learn steps: 366011\n",
            "ep: 4575  t: 2945067 ep_return: -3  smoothed ep_return: 0.05   ep_len: 643   smoothed ep_len: 641.9  eps: 0.05259845813877568 loss: 0.01809343323111534 learn steps: 368102\n",
            "ep: 4600  t: 2961309 ep_return: -2  smoothed ep_return: -0.29   ep_len: 669   smoothed ep_len: 649.69  eps: 0.05175105395620275 loss: 0.017893385142087936 learn steps: 370132\n",
            "ep: 4625  t: 2977245 ep_return: -2  smoothed ep_return: -0.4   ep_len: 796   smoothed ep_len: 657.29  eps: 0.05093288523446977 loss: 0.015079313889145851 learn steps: 372124\n",
            "ep: 4650  t: 2993764 ep_return: 5  smoothed ep_return: -0.27   ep_len: 398   smoothed ep_len: 654.24  eps: 0.05009843559793037 loss: 0.01825764961540699 learn steps: 374189\n",
            "ep: 4675  t: 3008608 ep_return: -4  smoothed ep_return: -0.15   ep_len: 485   smoothed ep_len: 635.41  eps: 0.05 loss: 0.02321019023656845 learn steps: 376044\n",
            "ep: 4700  t: 3024236 ep_return: -3  smoothed ep_return: 0.27   ep_len: 655   smoothed ep_len: 629.27  eps: 0.05 loss: 0.0211675725877285 learn steps: 377998\n",
            "ep: 4725  t: 3041310 ep_return: 2  smoothed ep_return: 0.31   ep_len: 760   smoothed ep_len: 640.65  eps: 0.05 loss: 0.016679683700203896 learn steps: 380132\n",
            "ep: 4750  t: 3057902 ep_return: -1  smoothed ep_return: 0.03   ep_len: 825   smoothed ep_len: 641.38  eps: 0.05 loss: 0.013979354873299599 learn steps: 382206\n",
            "ep: 4775  t: 3074006 ep_return: -3  smoothed ep_return: 0.07   ep_len: 555   smoothed ep_len: 653.98  eps: 0.05 loss: 0.016053644940257072 learn steps: 384219\n",
            "ep: 4800  t: 3089311 ep_return: 2  smoothed ep_return: -0.32   ep_len: 669   smoothed ep_len: 650.75  eps: 0.05 loss: 0.019818326458334923 learn steps: 386132\n",
            "ep: 4825  t: 3104829 ep_return: 4  smoothed ep_return: -0.39   ep_len: 476   smoothed ep_len: 635.19  eps: 0.05 loss: 0.02096870169043541 learn steps: 388072\n",
            "ep: 4850  t: 3120215 ep_return: -1  smoothed ep_return: 0.06   ep_len: 688   smoothed ep_len: 623.13  eps: 0.05 loss: 0.017999781295657158 learn steps: 389995\n",
            "ep: 4875  t: 3136518 ep_return: 2  smoothed ep_return: 0.21   ep_len: 714   smoothed ep_len: 625.12  eps: 0.05 loss: 0.0242911409586668 learn steps: 392033\n",
            "ep: 4900  t: 3153150 ep_return: 1  smoothed ep_return: 0.46   ep_len: 840   smoothed ep_len: 638.39  eps: 0.05 loss: 0.014334688894450665 learn steps: 394112\n",
            "ep: 4925  t: 3169604 ep_return: -2  smoothed ep_return: 0.65   ep_len: 705   smoothed ep_len: 647.75  eps: 0.05 loss: 0.019225623458623886 learn steps: 396169\n",
            "ep: 4950  t: 3185290 ep_return: 2  smoothed ep_return: 0.0   ep_len: 622   smoothed ep_len: 650.75  eps: 0.05 loss: 0.019610770046710968 learn steps: 398130\n",
            "ep: 4975  t: 3200487 ep_return: 4  smoothed ep_return: -0.41   ep_len: 574   smoothed ep_len: 639.69  eps: 0.05 loss: 0.023733045905828476 learn steps: 400029\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3QfONPnjV-gF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "a8e4b329-22c7-444a-aba4-3dbe8e5983a4"
      },
      "source": [
        "plt.plot(returns)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "l0ix6LbslAgM",
        "outputId": "00b9e8fa-2d4d-44f6-e3ce-2d92203f4f20"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fae64635790>]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO2dd5gURfrHvy+7ZJEMAgsuCoIgILACKipBEUTFnBUVD/U8PfVOhZ+Yw+F5Z/Y4UVEwYjxQFCUqIMElZ1hhybBLDktYduv3x1Tv9sx093Sc7pl+P8+zz/ZUV3dXdVe/XfXW+75FQggwDMMw4aCC3wVgGIZhkgcLfYZhmBDBQp9hGCZEsNBnGIYJESz0GYZhQkSm3wUwol69eiI7O9vvYjAMw6QU8+fP3ymEqK+1L9BCPzs7G7m5uX4Xg2EYJqUgog16+1i9wzAMEyJY6DMMw4SIhEKfiEYRUQERLVOl1SGiSUS0Vv6vLdOJiN4gojwiWkJEnVTHDJT51xLRQG+qwzAMwxhhpqf/IYC+MWlDAEwRQrQEMEX+BoB+AFrKv8EARgCRjwSApwB0BdAFwFPKh4JhGIZJHgmFvhDiVwC7Y5IHABgtt0cDuEKVPkZEmAOgFhE1AnAxgElCiN1CiD0AJiH+Q8IwDMN4jF2dfkMhxDa5vR1AQ7ndBMAmVb7NMk0vPQ4iGkxEuUSUW1hYaLN4DMMwjBaOJ3JFJEyna6E6hRAjhRA5Qoic+vU1zUwZhmEYm9gV+juk2gbyf4FM3wKgqSpflkzTS2cYhvGE7xZvxb7DxX4XI3DYFfrjASgWOAMBjFOl3yateLoB2CfVQD8B6ENEteUEbh+ZxjAM4zrrCg/i/s8W4qGxi/wuSuBI6JFLRJ8B6AGgHhFtRsQKZziAL4hoEIANAK6T2X8AcAmAPABFAO4AACHEbiJ6DsDvMt+zQojYyWGGYRhXOFJcCgDYuvewzyUJHgmFvhDiRp1dvTXyCgD36ZxnFIBRlkrHMAzDuAp75DIMw4QIFvoMwzAhgoU+wzBMiGChzzAMEyJY6DMMw4QIFvoMwzAhgoU+wzBMiGChzzAMEyJY6DMMw4QIFvoM4xI7Dx5FxCmdYYILC32GcYFNu4uQ8/xkvPPrOr+LwjCGsNBPEw4fK8Hyrfv8LkZo2bSnCAAwfXVBgpxMKjNtdQEmLtvudzEcwUI/Tfjbl4vQ/42Z2Ft0zO+iMEzacscHv+Oej+f7XQxHsNBPE+Zv2AOgPKSsghAC/1u4BUePl5SlLd60F6u2709q+RgmmQj3FvNLO1jopznT1xTiwbGL8PLE1WVpA96ehb6vzfCxVGkIyxgmRWCh7yKlpQJLN/urV4/t4eyXy8XtOHA0Lm9ewcGklClMEMjvIjDg52AEC30XGTVrPS57aybmrNuV9GvbaeQXvvKLByVhGCbIsNB3kRXbInryzXvsL9H20NhFyB4ywa0i4YNZ+QDKe/ypQGmpwKGjx/0uhi1Yl5w6FB44il/XFPpdjKTDQj9gfLtwi6vnW7RpLwBgx/4jrp7XCSWlwrA8r09Zi7ZP/ZRalkgpok0QQuDjORtw+FhJ4sxpzvXvzMZto+b5XYykw0LfZ77I3YQ1Ow64dr5UcAh9ZdJqdH1xCrbt0x4Rfbd4KwBg16EUEvopcN8BYPLKAgz73zK8NHGV30XxnXU7D/ldBF9goe8BVlzxH/1qCfq8+quHpYlAFJyu6C9ySL3zQAoJdZMEfQJRUZvtSaVRFOMqLPRdJAgvfIBkO8P4Bs+t6ONI6BPRX4loGREtJ6IHZVodIppERGvl/9oynYjoDSLKI6IlRNTJjQoEiSA0tFRQ7zBMuvJ7/m7c8t5cHC8pTZzZJ2wLfSI6A8CfAHQB0AHApUTUAsAQAFOEEC0BTJG/AaAfgJbybzCAEQ7K7RufzN2ArXvtW+d4hdLD33VQe9huJ/rj+MVbXZ1vsEoqfcBSqKihwK9R94OfL8LMvJ3YHiDDiVic9PRPBzBXCFEkhDgO4BcAVwEYAGC0zDMawBVyewCAMSLCHAC1iKiRg+snnd2HjuHxb5fpzvgHQb1z2VszNdPt6PQf+GyhJ/MNCYW5/7fRNurbvHTzPnw0O9/xObfsPYzXJq/hsM2MKzgR+ssAnEdEdYmoGoBLADQF0FAIsU3m2Q6godxuAmCT6vjNMi0KIhpMRLlElFtY6NyGtujYcTz21RLsK3Jup15SGnnpUsqUMAHJECTrCg/ime+Wo7Q0/YWW+nZe9tZMPDFuueNz3vvxfLw2eW3aelAXHTuOGWv9s5f34h0I8vfZttAXQqwE8BKAnwFMBLAIQElMHgGLI18hxEghRI4QIqd+/fp2i1fGp3M3YmzuJrw5da3jcwWZIHeOB380Hx/MyscfhRGhFTvoOHysJNpuPMAvjB527//Bo8dx7Lix/le5N27eliAJpf/7ZilufX8e1hWm50ctaDiayBVCvC+E6CyEOB/AHgBrAOxQ1DbyvxJgfAsiIwGFLJnmKU4b966DR7H/SDC9WbfuPZxQYCjo9WamrynExa/+imIPJ56UayvCPrYobZ+aiNOfnOjZ9ZOB3WZ2xlM/4eb35rhaFiOCaN2VJ4X9oaPsMJYMnFrvNJD/myGiz/8UwHgAA2WWgQDGye3xAG6TVjzdAOxTqYFcZ9u+w3h7Wp5ji5rOz09GlxcmAwiGdY7C4WMlOGf4VAz5egkA+0JnyNdLsHrHARRqBGRzG70PcJzWJ4CCySx2hOrv+XvcL4gORp2gJ8ctwzUjfktaWexw6OhxrHXZuCBIo55kkOnw+K+JqC6AYgD3CSH2EtFwAF8Q0SAAGwBcJ/P+gIjePw9AEYA7HF7bkHs+XoDFm/biupwsAM56OLEx6oMglY4UR3pFU02u1OSnc1aQHMOYCFqPZMzsDckvCKwJ3UGjf8ecdbuRP7y/8TkD1EELGo6EvhDiPI20XQB6a6QLAPc5uZ4ViqTnoR9zh340N7tiNZm9nLgOvc1Cr91xAEXHStChaS3HZQoqizbtxZjf8vGvazvE7Xt7Wh4anlgF13TO8qFkyeVIcQkmrdiBS9s3AhFhzrrdlo7nDkc8aeuRu8cFax19tCVlMtrXvsPFOODiHINSEz/ejUQfnP5vzNAMDHbRq79iwNuzPCqV+1z1n1llll9mufPD3/HNwi2a4RJe/mk1/v7lYlPnmZW3EwPenuXpnI1TjNreSxNX4f7PFuK3P+yFK1fmk8bMzseDny+0dQ4rpMI3Jm2F/s6DER21X89g9fYDnnjldXjmZ7R7+mfXzpcMXb6C1Wdx9HhpWbjqVCFfI4jXgo17HYW2tjoYKykVZcthPvrVEizetDdQUVatsG1vpNxW71+sz8yT45bjf4u2YvX2+PmAsCmC0lboK3jzQLXFl9JzXb/zEC5+7Vc8P2ElsodMwKdzN3pSCjVFxc4sH5LhWGZWvROdnBqvZKl8+Fv32ROu+TsPYdKKHdh10Pgj/PPy7QnP9drkNej72oyUWQfZjIrRrVZw8WveBzcEgj05nPZC34+efsH+yIs7TU6yvj5lDY6XlEYtTu42exOos/z05ox9BomKEuD3xRRHbHyAe/xrOv40JheXvBG9drFA9P0bNWt9wnOVr6Gg/wGx0hyOl5SaNg12glYnQM/MN3vIBKzYGryPGqt3Uhyrjcrogd/03ly0GqZvi251BR+rgtHLCa2iY8dNzTMkEjQbdsWrRmKP+WbBZitF84S7P8rFxGX6Pe7WT0zEnpi1AA4dO44+r/6C+RuMzTMVQa08rf9O/8P2R/CHJdvi1Dp2mkGvf/+C04b9GJW259AxzU7MwaPH8UXuJludDK1DjMo7b709PX/Bgeh74kaH6Mel26LWhwiy9VDaC/3yiUrrrT2212X1Oarb0rz1xlYHdlfwcUuUO/kmdH1hiqV5Br1rjZj+h+FxfxQexMNfmJvA9JKflu/APR/Pj0qLlRu7DkX3smf/sQtrdhzE1Rbt4N+bmbhnr8fY3E047oL52sbdRQAiwQYVOj43CXd++Htc3mHfLsWjXy3Bgo17HV9XjZtCdOCo+HI75d5PFuDq/wTbx0Eh7YW+XfRWdQISC8hkfuXNXslL9c4Bi+vZJiqK3u21ozYJCsk0HdS6lhuP//Fvl2H/keKyDsysvPiedoE0DLDzrKzeIqMqGb2DRu82EFFnJRqRRV1LYz4nCMEX9WChr8PZ/5hq+ZiZa3cCAL5Z4Hl0Cc+blPojkWhyMRFuybsgT47FEltWN26BG+dweg+LjpYgX0MNF1S0PoCJ7uPLP6/G1SN+w7It+0xdQ31PN+2OfFDMdvzmrtuF3UleFjTthb7ygPXizMdy8Ohx3DBytmEevRcnyDG0rfY01Qu0L9lc3vj3FRXj+ndmY0uCNQU27ipyJXJiCsl5Q5xaVwHKpK7+c9x18KjpEZ3dD7GXo1hNnb6qvnYmk83cj9gcq7ZFzDoLTXZ2nNyR60fOSShv3Cbthb7C1ws24+v5kUnA3/N3l/XKY5m2qsCS119ewQF0eWFy3OQQUB6KOZV6qApqyw91j2f8kq2Yu343/jMtT/fYY8dLcf7L03Dr+9HzFEGe3PKaJ/63zJXz6N3DNTsOoPPzk/HJ3I2WRwT7jxSX+bUkvL5Pj1CIiCeyWYw+jok6QFarqPVhsXKf1uxIbnTRtBf66ns/e11EB3ntf2fjlvfn2j6nus28P3M9Cg4cxeQV8TFwlN6w2R6DFWeuEqHE9nfHO9e0oDDRmt+dsS7m3PYVE+rLxV568SZ3JwuNWL/zUJxFjppkyMLYu5ibvxvZQyZgx/4j+EPG2tfrzMSivpfdXpyCnOcnmzquVAhLT7Po2HHT/gKaslim7TtcjNeneB8eve9rv5ZZ0pmp5/dLttr2FvaLtBf6XlMq5bRR58HsV//fk9aYvu60VeUfmYUbvY3SKFDem1EiQhrV10ko6mmrCvBHobbOOLaXO+DtWab1rk7p+a/p6PXv6Um5FhB9f/UWTxktA6R1fXFKWVqi0ZTWcyvSCHWhhxDaHzilfcS29fs+WYC+r81wPAn/3PcrHB2vxshvZJWGx64Rf/l0oSXLu31FxcgeMgFfz9/sm+8MC32HKC9ZBRdm2awIMLUp3pVumIoZlP+VSWtwkVw2cfzirTJ75IC8Ao2XJKYtx9rw64VWEAIY+/smzX3K/liSGV7A23hO5kg0avpp+Y4klSTCwo178N6MdWg+9Acs3xrffhVLH6emo0cT6PNz83fjobGLLAnSRPMaihpo0+4i/PaHuRFUIhTz1w9+s2+K65RQCf3Y9tDzX9MNh+xxx2ukKW05yCZabpBXcBA9Xp5W9lt5YRZtin/R1ffp24WbbYcmUHj0q8VybYR4SkVkMZlxi7y3mLJCsvtw6uuVmhR8m6QAsoq6pV/5n9/w/ISVAID5G/boClK7vdoDR/TNgdUjlIGj5uHbhVtwyMSoRc/LNxalQ3H+y9Nw07v21cFq1CMxv+ZHQiX0Y1m/81BZqIREbN17uGwYXXjgKH7Li3z5lQfnhlniIpVDS8H+IyiI6cVajdSoZmWiwGUmTp2/y7qQeGhsuTOVEjxLDyJgYkxsmWVb9uGL3M14+afVmscIIXDVf37DXz9fhHd+MXbuMsOyLftsepMGZ5JaS+if989pUb9nrC3Eef+chu+XbLV07mRX08hTXa9NAO4YDTz6lVygSJ7KzbAPm/ccNhVSwwvSXui71f+esir64/D8hJVRAqKCC1Jf7eTU5cUp6PLiFMz+Yxc+mp0PAJ7G7rEc1kH+f/fXdXH79ATgHRoenIl4VqXL1Trv4I/ml5nK/uPHVaatULSYvGIHLn1zJr7MtR7qwQ+Rr3efzYw6FVWV2hzXDGZHETe/NxdTV+mrmjbsOqQZdsMqz3y3HMUlpXH3/zfpOKZtqROd1vqJH/Hsd4nnDOI89A1IdJf2FhWXjZCASCwhN0OmG5H2Ql/N1ws24+nxy6PS7PZcVmzbj0vfnBkVj96M3J+4bBvu+3QBsodMQNGxxJ6sN747B0+MWx5XVr+VSYs370P2kAlYrbF0nd176kYgNrNCSYv1MizyGpeX47PDTpN+JVaYv2G34566lcM/mbNRxztY4IKXp+OCl6cDAJbLHvRsG1YwH8zKx5SV5R8XQmR08MIPK/UPUvLKopWKSCA7tztVh4+VoDRmdH75W/rrQGzecxhDv1mKJZu9tUoLldAHgA9/y9fdl7/zkG4YZD0hG7vodyLu+XgBJiyJLA3c5smfzB1kk/8tNK/njvMgTVCfRQbmkl71es0IrL/5FJvH74+wGr1nd/UI505AVtVYWvnfnKptbz9ppb1J6FhLZ7WTpNb19e6PUUBEq5QKgdOfnIhh48z7Z+wtKsZn8zbajsNllrQX+maa6IEjxdi8pwg9/jW9zJY/lmE6zjXqiVzPQyOotod8s9Qwb8H+I3hw7CJvC6SD3d7k2Fx9yx2zzDBpp+42sVX2Svet1z7N4nQU40a13J50FxCW7nfhgaOeqkqB8o/Np3M3YoHHJtVWSXuhb8YMss+rv6L7S9MS5jNiXv5uT/W6781YZ2jOGMsxi6t2Jctb1tmEZ3AmS4GIY57Svg4aWJnEsq4wYne/XmOVLQAYZGPuwyz/SRDJNBFWHp9AvE5996Fjun4Ybj1eM52vVsMmetxJKz/7VSZNqpMVky/thb4ZZ4ttDk0KgcgX3UvLhhd/WOnYQeVIcYnh5JpbGH1AFDt/APjHjystfQS0zEPd4ufl21FcWv6hPF5Sip+Wbzcs33Pfr8Clb84EANz/WfT6q0YvsGKzPm2VtuVYrNGAl1j/CBvnP16ivT9/Z8Ty65nvlmvu18KsQ5e6CqVC6I7K3cTqfRs4ah7aPGmsPkqWZVTaC/10wYq15ta9hzFlZbzgeHr8ctz5Ya7mMeoG9/Py7dhu80N4pLjE0LZabRs+K29XQqcbNW56ZSoIIfDQ2EUY/NF8vCo9ogUisf3v/mg+Jq2I/khqrYGrZTGUbNNGu9f7cr41S6XXp+ThHQ2LLYV5+eVxq6auKsBBaZF22VuRj2OiBdoPHT1eZuCg7iAYoa76qJn5ptuUmVu2V2NhesB4blDr7L+sKTTt+ex1hz/TycFE9BCAuxCp4VIAdwBoBOBzAHUBzAdwqxDiGBFVBjAGQGcAuwBcL4TId3J9NwiWwsAdLn9rlqYgMgqJq74Pgz+ar5svEX1e/bXM69AMyVxe7on/LUOpEHjhynZlafPW7y6LKFqs6qUqcZN2xTjvaenEzcatUfD6g2BlXkMrdtP+I8U4UlyCBjWqxO37zkAQO32UAgJtn/oJVSpWwKrn+tk6x6uTzYcyMcNfPl2omT5+8VbccW5z3eMC5LYRh+2ePhE1AfAAgBwhxBkAMgDcAOAlAK8KIVoA2ANgkDxkEIA9Mv1VmS/lCeKztWurvnr7AXzg0GHEisBPNh/N2YBPYqyzDmosAGMkvNxYDMXu/InRJO5T491TaZz30jR0eWFK4owx2KmVVuiGI8Wl2H+kGGtNTjoLIXTvKRHp+gOYeZJbdRZcWbhxL9o9rW9959QL3Usc9fTl8VWJqBhANQDbAPQCcJPcPxrA0wBGABggtwHgKwBvERGJILky2sCo5xM0jEJGCyFw8Wu/JrE0ynWTfskotByxIgHmIttDv1ka5fnp50ImowyWTnTTrn/f4Ujvv7ikFBUz3NUAx9q49X9jpua+K9+epT/ha4GV2/aX+QPYwehZGakxZ7qwloRX2H6iQogtAP4FYCMiwn4fIuqcvUII5W5sBtBEbjcBsEkee1zmrxt7XiIaTES5RJRbWBjcG8fEYybUcexL9OZU78PlGrFuZ+JY5uqVjTa4MJKxG7ojmUsuAsCT48xPugLu6qLdEPiJMDNPZrdP+u4M/wKqJcKJeqc2Ir335gAaA6gOoK/TAgkhRgohcoQQOfXr13d6OsYkbvS4B7yt722ox9vTnMfLiWVfUTF6vDwNgz78HYUHjFVdWvUuKRW6w/o1FkPval5TqiIOWVxbONl8Nm+jYeybWMw0ISPVll21l5ejxZRWQ+jgZOx2IYD1QohCIUQxgG8AnAugFhEpaqMsAIonxhYATQFA7q+JyIQuw7jKzLydyN9VhCmrCnDWC/GTrHNVunGtl/rD3/J1J0PNdrbNzKv862drk45+eP1a8Q61OjJwi2Qv4eg1R4pL8crPq20tD2kGJ0J/I4BuRFSNIuPO3gBWAJgG4BqZZyCAcXJ7vPwNuX9qEPT5AShCqAjC3b5+5ByMmZ1v61izQv/m9/RD8Ya5yXnht+5tTz/5D+twcQnemJqHT+Zu8OT8TnT6cxGZkF2AiLlmBQAjATwG4GEiykNEZ/++POR9AHVl+sMAhjgoN+My6SSIzLyofvVKFWIDcdkhjR4ZAGeB+o4Ue9MrLvXmtKbwqqfvyHpHCPEUgKdiktcB6KKR9wiAa51cj0l9XrGwJKRb7Dp4NMoGX43Vkd5UF7xlhSj3A7DC5j3Wj0klcjfYi1Hj5cfPznOyy88rtifO5AJOTTaZNMGPYWyy6Pz8ZJxSv7rmPqu13rHffrz+8msKfDZPO5qrEbHxlNSL7qQKThYCSnc+mJWflOuw0GcAwJEtcyqQaNWuZHLtf2dbCj+hRzJ7oW5xyMQaElbheTlrhD72jtWVgxjGKW4IfKacR+SyhumGV24ZoRf6H83xZoac8Q+tjp/uC8SdRCZkhF7oM+nH7kPmQxKwzE8uyfYqZuJhoc+kHU+NjzfH1Apre6S4RHchE8Z99MIUM8mFhT4TWpJlLcFEePzbZZbCOjDewEKfCS1eOb8w2kxYus3vIqQUXq26zUKfCS3p7JvAMHqw0GcYhgkRLPSZ0MI+PUwYYaHPMAwTIljoM6GFO/pMGGGhzzAMEyJY6DPhhZX6TIDh2DsM4zJH2E6fCSEs9JnQMvLXdX4XgWGSDgt9hmGYEMFCn2EYJkSw0GcYhgkRLPQZhmFCBAt9hmGYEGFb6BNRKyJapPrbT0QPElEdIppERGvl/9oyPxHRG0SUR0RLiKiTe9VgGIZhzGBb6AshVgshzhRCnAmgM4AiAN8CGAJgihCiJYAp8jcA9APQUv4NBjDCScEZhmEY67il3ukN4A8hxAYAAwCMlumjAVwhtwcAGCMizAFQi4gauXR9hmEYxgRuCf0bAHwmtxsKIZQlcrYDaCi3mwDYpDpms0yLgogGE1EuEeUWFvLSagzDMG7iWOgTUSUAlwP4MnafEELAYjBDIcRIIUSOECKnfv36TovHMAzDqHCjp98PwAIhxA75e4eitpH/C2T6FgBNVcdlyTSGYRgmSbgh9G9EuWoHAMYDGCi3BwIYp0q/TVrxdAOwT6UGYhiGYVSQR2E2M50cTETVAVwE4G5V8nAAXxDRIAAbAFwn038AcAmAPEQsfe5wcm2GYRjGOo6EvhDiEIC6MWm7ELHmic0rANzn5HoMwzCMM9gjl2EYJkSw0GcYhgkRLPQZhmECiEerJbLQZxiGCRMs9BmGYUIEC32GYZgQwUKfYRgmgHjkm8VCn2EYJogIS1HLzMNCn2EYJkSw0GcYhgkgrN5hGIYJEVv2HPbkvCz0GYZhAsh7M9d7cl4W+gzDMCGChT7DMEyIYKHPMAwTIljoMwzDhAgW+gzDMCGChT7DMEyIYKHPMAwTIljoMwzDhAgW+gzDMCGChT7DMEyIcCT0iagWEX1FRKuIaCURnU1EdYhoEhGtlf9ry7xERG8QUR4RLSGiTu5UgWEYhjGL057+6wAmCiFaA+gAYCWAIQCmCCFaApgifwNAPwAt5d9gACMcXpthGIaxiG2hT0Q1AZwP4H0AEEIcE0LsBTAAwGiZbTSAK+T2AABjRIQ5AGoRUSPbJWcYhmEs46Sn3xxAIYAPiGghEb1HRNUBNBRCbJN5tgNoKLebANikOn6zTIuCiAYTUS4R5RYWFjooHsMwDBOLE6GfCaATgBFCiI4ADqFclQMAEEIIAJYW/RJCjBRC5AghcurXr++geAzDMEwsToT+ZgCbhRBz5e+vEPkI7FDUNvJ/gdy/BUBT1fFZMo1hGIZJEraFvhBiO4BNRNRKJvUGsALAeAADZdpAAOPk9ngAt0krnm4A9qnUQAzDMEwSyHR4/P0APiGiSgDWAbgDkQ/JF0Q0CMAGANfJvD8AuARAHoAimZdhGIZJIo6EvhBiEYAcjV29NfIKAPc5uR7DMAzjDPbIZRiGCREs9BmGYUIEC32GYZgQkZZCv2D/Eb+LwDAME0jSUujvLjrmdxEYhmECSVoKfYZhGEYbFvoMwzAhgoU+wzBMiGChzzAMEyJY6DMMw4QIFvoMwzAhgoU+wzBMiGChzzAMEyJY6DMMw7hIxQzyuwiGsNBnGIZxkQtPb5g4k4+kpdAnBPtLyzBM+vJA75Z+F8GQtBT6DMMwfnFCZacLEnpLWgr9Y8dL/S4CwzAhRQi/S2BMWgr9ldv2+10EhmGYQJKWQp9hGMYvBILd1U9Poc/zuIyKT+/q6ncRGCYwpKfQZxgVp9Q/we8iMExgcCT0iSifiJYS0SIiypVpdYhoEhGtlf9ry3QiojeIKI+IlhBRJzcqoFkur07MpCTEDYJhynCjp99TCHGmECJH/h4CYIoQoiWAKfI3APQD0FL+DQYwwoVra0Ihf8sb1KjsdxECRbhbA5Nswmi9MwDAaLk9GsAVqvQxIsIcALWIqJEH1w89bRqf6HcRGCaKoNuu+0lW7apJvZ5ToS8A/ExE84losExrKITYJre3A1B8kpsA2KQ6drNMi4KIBhNRLhHlFhYW2ioU9+wYJlj0PeMkv4uQNKx29K/ulOVJOfRwKvS7CyE6IaK6uY+IzlfvFEIIWLwHQoiRQogcIURO/fr1bRUq5Nod/uhJMivIO8E3xHf6tg2P0LdKsrVBjoS+EGKL/F8A4FsAXQDsUNQ28n+BzL4FQFPV4VkyjXGZgKsUkw7HYmKSibCo1E9267Qt9ImoOhHVULYB9AGwDMB4AANltoEAxsnt8QBuk1Y83QDsU6mBXCXsPX0mGm4PjJrLOzT2uwhRJLt9OunpNwQwk4gWA5gHYIIQYiKA4QAuIqK1AC6UvwHgBwDrAOQBeBfAnz4YxfoAABbLSURBVB1cmzGAZRwDAA/0auF3EXxjztDeuvvC3gmwPaUuhFgHoING+i4AcXdc6vfvs3s9K/BwngFYzdW9ZX28MTXP72J4Slbtqti853Bc+kk1q/hQmtSAPXKZtKFNI21T1bB2AepUr+R3EcogAipnui9uqlTMcP2cTgl6Z4OFfkCZ9ND5munts2omPNZr57Qh/Vp7en63SVdnve/v7264P02r7Zig3ZYMnQd1wWn2rBcTkZZCPx0ae8uGNTTTg1C1ZDuTMNok6jkno62c2bSWqXxB91JVc21nZ3bzVutaW2dE5pUcS0uhX72Sf95/Z2XXtpS/9Unawl0PO+/O05e1sXGU/1S1OHSPvTc3dWkGAKhWKXgqgGSQDDlb30LIDy/KY8Y8smUDawH3Xriynd3ipARpKfS7t6znynk+uP2suLTH+hqrNto1MdfzUfguwRA9Fjs9pux61a0fFAAqOOzpPHN5W6x49uKEet93b8vBjV2a4aWrk/Oyn1KvOvqFyENVYcTNnsVYNOSHv55n+ZiPBnUxla9SRuqJ0NQrsQmqVMzA54O7RaX98ID2gz+1vr5A7Nm6QVzavT1OdVY4FW/e2BEVXW4012gMTcMSiye211ehAqGaiVHfRW0a4h9XtUOPVvHP2wu+u787RtzS2fPrJEOlYvYaRMDpOhPtXhP7jhnN8fRq3QCVMivgvJbm9Ok5Fkf2QSAthT4AdDulbtRvPcHXoEbEtGv4VeZ7eW0DLEQb16papst9dkBb5A67sKyObuFUmGTXreZOQWJw+gFN1nxJdQfBx05W3bsUUpMHCqPnPEpjdG8dd56MV+0xbYW+VaxMmkzQGTUAQLdT6rhQGmt0UE2mqavRuGZV1DsheGGW/++S010/50tXt0PjWulvm61+vomfrbbw+fSurnjyUvfnee7r6d4o2Cx+f/jcmGxNJY/cUPDebTmJM0nObFoLfdqehEVPXuRhiaJpUivakkbdgLx6IYJoHXX9Wc1SykIkltvOPtl03i7ZkY6FXTv8c1rUw+Vnuh+K4JGLzZvyXnh6clRpXlNB42UIejvkINcJuLBNw8SZJLefkw0AqFXN3MuY6XSmUkHVyoLijdyuSU0s3bIvKdfq2Sqif3X8rvl46y7v0BhjZm8wlXfs3d0CI1iIgLdv6oSiY8cT5vWiyK69Qza44aymuLJjE8xYu9PReZJdh9D39P3stV5k4YOiB1H0y6Suj1dVMyNwPvmT8WLkEx7ojioVjZvfsEvbIMPEC/HBHeYsLdIFIkIFE/elcS3v/SmEAPq3b4Rrc5omzuwy9/Y4FZe1tzFi0bl1kx++QPeQmY/1xN0XnBKVNvzq9qhZrWL86S2+eFelWDz9lMfNHlMLC/bAl3VojEyXLHfUdVC3Nz87gydWiX8ZFIgIbRvXxK3djFUaN3Zphj9evMTtogUSI0Hxo4HJYW8NCzMAOKPJiaYsl7TQC2fhNk9c2gadT7Zv/fJY39bIyLDetdEbDeu9v/+8pj2yalfTvC9a8sOqTNEzQPDKkzz0Ql/BDbXIGU0Sh0gov549RIwoj21gRMHUuWvhdqNW34tXr4+LBRgIHr7oNMvHqE0dY++ZnulnUNR8atQmtUIAg7o3x9f3nuNjicxxnRzFXNa+MZqnqM+LGhb6PuFE3j1/xRlRv9UfgmTEmXEawZBi/ruH+2ObrNpVLXt0GnFz12aW8tfSUB+oqaQTikGvGQTFKcwt/xQ7H7fYjpNZKlQgU86UZs7+z6vb2yqDG7DQV0hyx8jKQtEvXxPdQG6JUYuoe7jqIarVFXyM6KOafzgruw6+uPtsx+e8zMPFLOwIA61jZj7Wy7LXtBFaTyR/eH/oNUBlkm/K3yL6ZifNtGbViklxCjPD81eekTiTCewIcCejoNj31uwr1rRO+fwKEXDdWcmfA1EIvdDv0jxi/uZmby4Rj1zcCkMt2KqfXNd4SKk0vH9f2wEXJ2ktUuW+2aGZdDA6o0lNKfDcwegFdFLeVOTsU+smzuQCVjzUlVFo45pVDH0MzEzeO8HrwXCzOvHOh2rfHr8Vb6EX+jd3a4bZQ3uhY7PEE0pueeLe17OFpZ5+K1XEzcqZ8XFkFFnXKiZ4m5uqHrdO9cHtZ+E0nQiiXvLmjR3Ltic/fAEWP9kn6WWwg/Ihq1c9IiTN2tcPOre5/WuazPfvaztYmog1O/KsklkBNUy+H36brsaONN68saNmrCe1YYPfob5DK/Svz2mKD24/Cw1qVEGjmvGmbVrP5e99WiWhZPaJLbMV9c77A807oTlBK56RFxi9V9UrZ2ia2vnJyTqhKZQnWLNaRax49mL8tXdLcyd0IFe8Fkl+Cr0OTWuhRytv4tSr+fbP50SpRINEaIX+yfWqGQqgmlWDIxROrFre69F6XeKFu/WXqqoH4YeTHQIiIP5Ktqh3QmXkD+9vGKq4WqVMRwLT7KFm72OQ7vf5JhcceevGjqiiMVq2i978QMdmtXU/5GafIMfeCTjf/Nk70zP1i270osU2QCcvZV0TLv43JJiMmvzw+WhnwYzVKUYjG7/VAGaJ9c50czI++ryenNa3a1pRvbrZwYlV72RrzL/96bxoVVvDE81Zv3X1KI4XC30VN6nM6ax+ZTuZmBPwCuVlUr4Nboyef3m0Z8I8wxOYndWqVklzUiuWm7o2w4MXRqstrCzOoYWdeQO9+5ZMbUSQRpix+BFQzW2IgHNOrYvnBrR19bytT6qBGY/2RDuN5Uxj2/KX9yS2fJv5WE/86bxTEuazQyiEvlaMea1h2YtXtsNvQ3pF9qeKh5MKu0VupSEgrUw0O+XFK9vhwQvLnZYubd8I3/3FuplkU9UHxq/Y7Wo+vasrZjzaE0uf7lO2tGGyetha7dvsta14lpvF69fJyumJCLeene3u9Ymi2p8RZsJjZNWuFlyPXCLKIKKFRPS9/N2ciOYSUR4RjSWiSjK9svydJ/dnO722WWLt3AGgoo77tuLsElSRr6UusWOrrNgNP9a3NSY+aG5loU/v6oph/d0PixzL+S3r23IAu+eCSE/0FIOFcexQOTMD9/dqYfm4c1rUQ9M61VCjSkXUqGLvI2r3G2HXAQkAnr08vhes5TnrlerpAbOT1QHAi1tg9n20ixs9/b8CWKn6/RKAV4UQLQDsATBIpg8CsEemvyrzJQWtL+atOqFsDR9iAL4Ej8cI3as7Z5WrdywUUJnMioRtMHfcOS3q4S6rQ06X75narv/6nKZRaxI3rlUVj/VtjdEaAdiiQk7beFH/1qeV4+UbvSbR0n3qe2Ck166sEQjPSYwcwPw9Pyu7Nu6+IPXUSG42jdYneTtKdST0iSgLQH8A78nfBKAXgK9kltEArpDbA+RvyP29yScdypUdm2jau6txo2Tql/C6HHci6cW6r7dpdGJZn85smU86sUqc5VL7LGtr+yaTof0icdpjJ8ReuqY9vrwnugd6b49TNYfZXqlVqlbMiPoQ6U2A92/XCID1RdqtlHvNC/1M57WjvlMEf8MTvbPKchIZ9KpOTRLmUb+TI2/tjO9d9LaOxU6bm/d4b/cLEoPTnv5rAB4FUCp/1wWwVwihBNfeDEB5Ek0AbAIAuX+fzB8FEQ0molwiyi0sLHRYvGjMLIlodlj8aF9jm/3Rd3Ypc50HInprM7x8TXvccW62qbwKyjA7VuarG90vj/TAx4O6YsETF2H20F5leZU8J1TOxC+P9LB0Xc+IqUiyuwZ68c3H3Nk1Yeyad27VDnPw5GVtsejJiywvlWhXhWJm1PfKdeaC0imqwF6tG2L+sAtxbot6tspkBqVTc1O3+BhF6g+V8uFR359Xrjsz4fkbqCxn+rQ9yVKQRC2UMhmpFK2MwN1e2lQL27N1RHQpgAIhxHwi6uFWgYQQIwGMBICcnBxX+2d6wamiC6BslD+o81rWi1soIdHDuSDGbjgzowJmPNoT+w4XGx5nJy75Hec2x7D/LUNDqQfXamIn160eHc5BI5NRuAe78UqeuqwNTqiUibG5m8wfpPPUvZ4EVWp4YtWK2H3oWNz+7i3roXvLesgeMqH8GJ3bUj2mR59RgUwvrmOVF69slzAwmxZXdcrCsi37MWrW+qj0WDXR9L+XW3LVPaGyvbhGpL0NAM8NaItf1uzE5JU7ytKG9G2Nv/dphZaP/1iWpgj4b/58DjrEjEyddAz+e0snFB6Mf95myK5XHaPv7BKlZlSoKOWN12ElrOKkp38ugMuJKB/A54iodV4HUIuIlI9JFoAtcnsLgKYAIPfXBLDLwfUto6h0qlfWH2Irus7zWpb3ZtzSQjWtU81xz0KLW7qdjPzh/Q1j2JtlUPfmZUswXmHC5T9/eH9MfviCqAVh/qYKH9ygRhW8dE17vH7DmRh9p/FiJ61PMmdm2SGrJi73MFibG7R2aD30nIykep4Jp6ObujbDJVJ9FEtPi96n+cP7IzOjQtn1AX2hpRc8bvXzfZGt45ikxa1nZ6NP22jvVSJCxYwKUeoO5XqZFaisTH3lyKt/u/j2MO3vPUypS/qe0Sjh2g5GXHBafc21C/7SswX+dF7zKFPwIGBb6AshhgohsoQQ2QBuADBVCHEzgGkArpHZBgIYJ7fHy9+Q+6cKr6b/JV/dczZG3V4eXqDvGSfhsb6tMaSfvgVKjSoVMf3vPTD86nh1jFffay3rokQoDUlLR6wMv41ifyt+BWc0iRZOT1zaBrOk2eprN3TEiJs7JSxLiwYnlHnfvnDlGbhfw/piwJlN4kY/sZR9EBPYy4/7S3e8oYqlY4ZMHWst9VqtyoubKGjdmzd2xNf3RmytY1uwYnWUqK6J6NysNn55pAf+fa29dQGUdjHils6Y9vceaFKrKl64Ir5N39S1WdyoBIChEEzUB6qcmYHpj/TEzw+db/mjE0uDGlUw6vYcNKhRuUzfrx5ptGhQA/nD+6ONdM66/ZzssuitzetV90Rd8sldXfHJXcYrwwFA9cqZeLx/G81YPArtNez6vcYLY+zHAHxORM8DWAjgfZn+PoCPiCgPwG5EPhSekpMd7dGWUYFMRQXMNrFQgtoD8K2brAmgWK7NaYpHvlpi6Zhh/U9H+yY1o0YkCredfTL6nnGSoeffxW1Pwtz/653QO7B7y3rokFUTf+tjvPhHIynszHjy2sVJF0ErJMSCJy6K0hNXrZSB3GEXolbVivhs3kbdc13WobHumrBZtath3uO9ywKkWeXFq9rhHz+sxKkNqic0NjBCmTuoUjEDzetVL/uQx9KiwQlY9szFaD70B9PnbiyfdZ0E6qpYB7lGNaug2yl18NCF+m1J6xn3at0Q8x5viEtenwHA+KPztIa5qdu4Naex6MmLDD8IXuGK0BdCTAcwXW6vAxA3jhdCHAFwrRvXCwKnNzoRK5/t65pL998uOs2SQ1G1Spm4oYv2sJGITLl6m8lTo0pFjDPhKPXnHqeiRYMTPAnt7NYqUEP7tcY/flxVpv+uo/GBciNekJPeZadmteMskqzw31s6Y93Og7aPN8P9vVvi9EYnovfpiYPnKUuCEgiZGRXw+WBtb9Rgab2Tg1dzPIlInttlCqOnhTIj8D+4/SzsKUo8SaSlElEz+eHzcULl4LroZ2ZU0NUrm6Vt4xPx1fz4eOTKAupOe0V3X3BqoGzAc06u7XpPr28SVsaqmFEB/Uw+6xevbIeT61QzHRDNiBQJn2SL34b0wuHikqRci4W+x7gVSrhFg+THoE82t5+TjS7N66Bt42g95/VnNcOuQ8dw9/nBEdixjP/LuVi/85ClY74K+Pqw559WH6c4XBO2fo3KGHZpG9P5jUymy0yT03BY4MQ/wSos9APMDw+ch50Hj/pdjKRBRHECH4iY2j5ooAf2gu/v7469RcbmtWraZ9UKtINbIro2r4M7YhZeGZPA2spNrFjIBXHRdzN8+qeuqK5h5ZNs/C9BCpFsB+I2Lq3UxVgnkWmtYstu1ZEuiBARxrqw5rHXxEaTTTXOOdU7pzYrsNBnGBtkZlRwdX3fsNNFWtpd3Uk/XImi+rEj9Hu3boA1BQdslS3dYKFvgnsuOBUz1u5M6oIgDBMmmtWtlvAjaiewoML7t59lp1hpCQt9E5zboh736hgmIKSqeicohGIRFYZhUp9XrjsTvVs3MPQ0ZxLDPX2GYVKCdlk1WU3jAiz0GYZhNPj2z+dg5bb0m/xloc8wDKNBx2a10bGZsxXDggjr9BmGYUIEC32GYZgQwUKfYRgmRLDQZxiGCREs9BmGYUIEC32GYZgQwUKfYRgmRLDQZxiGCRGktxRgECCiQgAbHJyiHoCdLhUnFQhbfQGuc1jgOlvjZCGE5hqVgRb6TiGiXCFEjt/lSBZhqy/AdQ4LXGf3YPUOwzBMiGChzzAMEyLSXeiP9LsASSZs9QW4zmGB6+wSaa3TZxiGYaJJ954+wzAMo4KFPsMwTIhIS6FPRH2JaDUR5RHREL/L4wQiGkVEBUS0TJVWh4gmEdFa+b+2TCciekPWewkRdVIdM1DmX0tEA/2oi1mIqCkRTSOiFUS0nIj+KtPTst5EVIWI5hHRYlnfZ2R6cyKaK+s1logqyfTK8nee3J+tOtdQmb6aiC72p0bmIaIMIlpIRN/L32ldZyLKJ6KlRLSIiHJlWnLbtRAirf4AZAD4A8ApACoBWAygjd/lclCf8wF0ArBMlfZPAEPk9hAAL8ntSwD8CIAAdAMwV6bXAbBO/q8tt2v7XTeDOjcC0Elu1wCwBkCbdK23LPcJcrsigLmyHl8AuEGm/xfAvXL7zwD+K7dvADBWbreR7b0ygObyPcjwu34J6v4wgE8BfC9/p3WdAeQDqBeTltR27ftN8OCmng3gJ9XvoQCG+l0uh3XKjhH6qwE0ktuNAKyW2+8AuDE2H4AbAbyjSo/KF/Q/AOMAXBSGegOoBmABgK6IeGNmyvSydg3gJwBny+1MmY9i27o6XxD/AGQBmAKgF4DvZR3Svc5aQj+p7Tod1TtNAGxS/d4s09KJhkKIbXJ7O4CGcluv7il7T+QwviMivd+0rbdUcywCUABgEiI91r1CiOMyi7rsZfWS+/cBqIsUqq/kNQCPAiiVv+si/essAPxMRPOJaLBMS2q75oXRUxwhhCCitLS7JaITAHwN4EEhxH4iKtuXbvUWQpQAOJOIagH4FkBrn4vkKUR0KYACIcR8Iurhd3mSSHchxBYiagBgEhGtUu9MRrtOx57+FgBNVb+zZFo6sYOIGgGA/F8g0/XqnnL3hIgqIiLwPxFCfCOT077eQoi9AKYhotqoRURKx0xd9rJ6yf01AexCatX3XACXE1E+gM8RUfG8jvSuM4QQW+T/AkQ+7l2Q5HadjkL/dwAtpRVAJUQmfcb7XCa3GQ9AmbEfiIjOW0m/Tc76dwOwTw4bfwLQh4hqS8uAPjItkFCkS/8+gJVCiFdUu9Ky3kRUX/bwQURVEZm/WImI8L9GZoutr3IfrgEwVUSUu+MB3CAtXZoDaAlgXnJqYQ0hxFAhRJYQIhuRd3SqEOJmpHGdiag6EdVQthFpj8uQ7Hbt98SGR5MllyBi8fEHgMf9Lo/DunwGYBuAYkR0d4MQ0WVOAbAWwGQAdWReAvC2rPdSADmq89wJIE/+3eF3vRLUuTsius8lABbJv0vStd4A2gNYKOu7DMCTMv0URARYHoAvAVSW6VXk7zy5/xTVuR6X92E1gH5+181k/Xug3Honbess67ZY/i1XZFOy2zWHYWAYhgkR6ajeYRiGYXRgoc8wDBMiWOgzDMOECBb6DMMwIYKFPsMwTIhgoc8wDBMiWOgzDMOEiP8HxbU7GGzNXTkAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jSAA3aVamJ8W"
      },
      "source": [
        "  N = len(returns)\n",
        "  running_avg_returns = np.empty(N)\n",
        "  for t in range(N):\n",
        "    running_avg_returns[t] = np.mean(returns[max(0, t-20):(t+1)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5vb53xynHiz"
      },
      "source": [
        "  N = len(lens)\n",
        "  running_avg_lens = np.empty(N)\n",
        "  for t in range(N):\n",
        "    running_avg_lens[t] = np.mean(lens[max(0, t-20):(t+1)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9OAcODClmjDh"
      },
      "source": [
        "np.savetxt(\"multi_slime_av_ret.csv\", running_avg_returns, delimiter = ',')\n",
        "np.savetxt(\"multi_slime_ret.csv\", returns, delimiter = ',')\n",
        "np.savetxt(\"multi_slime_av_len.csv\", running_avg_lens, delimiter = ',')\n",
        "np.savetxt(\"multi_slime_len.csv\", lens, delimiter = ',')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h75tJnwomnk-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}